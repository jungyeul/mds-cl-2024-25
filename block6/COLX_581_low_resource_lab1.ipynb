{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colx 581 Lab 1: Crosslingual Transfer for Danish NER (Cheat sheet)\n",
    "\n",
    "In this lab, we will build a named entity recognizer (NER) for Danish using a small dataset of named entity (NE) annotated text for Danish and a larger dataset of NE annotated text for English. We will use the [spaCy](https://v2.spacy.io/) toolkit which you should first install. You can use either SpaCy version 2 or 3 for this assignment. Please see practical work 1 on Canvas for how to install this version.\n",
    "\n",
    "In the first assignment, you need to build a function which **reads data** and another function which **converts the data into spaCy format**. You'll also create tests to check that your data handling works properly. Finally, you will create an **evaluation function** for NER.\n",
    "\n",
    "In the second assignment, you'll **train a spaCy NER model** on a small dataset of NER annotations and evaluate your NER model on Danish development data.\n",
    "\n",
    "In the third assignment, you'll first **train a NER model on English** NE annotated data and aligned bilingual word embeddings for Danish and English. You will then **fine-tune your model on the Danish NE** train set and finally evaluate you recognizer on the Danish test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1. Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1.1 Reading data from disk\n",
    "\n",
    "rubric={accuracy:5}\n",
    "\n",
    "The directory in `Lab1/data` contains Danish training, development and test data for NER in a simple two column format (where a tab separates the columns). All tokens are marked with BIO tags and the data contains four entity types: `LOC` (locations), `MISC` (miscellaneous), `ORG` (organizations) and `PER` (person names):\n",
    "\n",
    "```\n",
    "Berlingske      B-ORG\n",
    "Tidendes        O\n",
    "afslag          O\n",
    "kom             O\n",
    "først           O\n",
    "seks            O\n",
    "uger            O\n",
    "senere          O\n",
    "og              O\n",
    "lignede         O\n",
    "til             O\n",
    "forveksling     O\n",
    "afslaget        O\n",
    "fra             O\n",
    "Jyllands-Posten B-ORG\n",
    ".               O\n",
    "```\n",
    "\n",
    "Sentences are separated by blank lines.\n",
    "\n",
    "Define a function `read_data` which takes a file as input and returns a list of sentences. Each sentence is a list of pairs `(token, bio_tag)`, for example `(\"Jyllands-Posten\", \"B-ORG\")`.  \n",
    "\n",
    "**You should also write 3 tests** in addition to the existing test below for `read_data`. You can imitate the test below `read_data`. These tests use the class [`io.StringIO`](https://docs.python.org/3/library/io.html#io.StringIO) which provides a file-like interface to strings.\n",
    "\n",
    "You should test that `read_data` does something sensible when given an empty file and a file with more than one sentence. You should also check that your implementation can handle a blank line at the end of the file correctly (we don't want empty sentences in the returned list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "\n",
    "def read_data(file):\n",
    "    data = [[]]\n",
    "    # your code here\n",
    "\n",
    "    # your code here\n",
    "    return data\n",
    "\n",
    "import io\n",
    "\n",
    "# A test to make sure that your read_data function can handle a file \n",
    "# which consists of a single sentence. \n",
    "test_string = \"Berlingske\\tB-ORG\"\n",
    "assert(read_data(io.StringIO(test_string)) == [[(\"Berlingske\",\"B-ORG\")]])\n",
    "\n",
    "# You should write three additional tests here:\n",
    "# your code here\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now read the Danish training, development and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('På', 'O'), ('fredag', 'O'), ('har', 'O'), ('SID', 'B-ORG'), ('inviteret', 'O'), ('til', 'O'), ('reception', 'O'), ('i', 'O'), ('SID-huset', 'O'), ('i', 'O'), ('anledning', 'O'), ('af', 'O'), ('at', 'O'), ('formanden', 'O'), ('Kjeld', 'B-PER'), ('Christensen', 'I-PER'), ('går', 'O'), ('ind', 'O'), ('i', 'O'), ('de', 'O'), ('glade', 'O'), ('tressere', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "danish_train = read_data(open(path.join(\"data\",\"danish-train.conll\")))\n",
    "danish_dev = read_data(open(path.join(\"data\",\"danish-dev.conll\")))\n",
    "danish_test = read_data(open(path.join(\"data\",\"danish-test.conll\")))\n",
    "\n",
    "print(danish_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1.2 Converting data into spaCy format\n",
    "\n",
    "rubric={accuracy:10}\n",
    "\n",
    "The NER models in spaCy take training data in a specific format which differs from the BIO annotation in our files:\n",
    "\n",
    "```\n",
    "('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .', {'entities': [[14, 17, 'ORG'], [88, 99, 'PER']]})\n",
    "```\n",
    "\n",
    "Each example is a pair where the first member is a sentence string like `'På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'`. Note that the tokens in the sentence including punctuation are separated by spaces. The second member is a dictionary which specifies all named entities in a list `{'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]}`.\n",
    "\n",
    "Each entity like `[14, 17, 'ORG']` gives the start index of the entity (`14` in this case), its end (`17`) and the type of the entity `ORG`. The organization here is \n",
    "\n",
    "```\n",
    "print('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[14:17])\n",
    "\n",
    "SID\n",
    "```\n",
    "and the person is:\n",
    "```\n",
    "print('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[88:99])\n",
    "\n",
    "Kjeld Christensen\n",
    "```\n",
    "\n",
    "It is your task to define a function `get_spacy_ner_data` which takes a dataset in BIO-format and returns it in spaCy format.\n",
    "\n",
    "**You should also write 5 tests** in addition to the existing test below for `get_spacy_ner_data`. You can model your tests according to example that is given. Your tests should cover at least the following cases: \n",
    "\n",
    "1. A sentence with a single entity consisting of one token.\n",
    "1. A sentence with multiple entites \n",
    "1. A sentence with an entity containing several tokens.\n",
    "1. a sentence with two entities next to each other like *Anne showed Sue Mengqiu Huang 's new painting* (note the space after *Huang*), where *Anne*, *Sue* and *Mengqiu Huang* are all separate person names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID \tORG\n",
      "Kjeld Chris \tPER\n"
     ]
    }
   ],
   "source": [
    "print('På fredag har SID inviteret til reception i SID-huset \\\n",
    "      i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[14:17], \"\\tORG\")\n",
    "\n",
    "print('På fredag har SID inviteret til reception i SID-huset i \\\n",
    "      anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[88:99], \"\\tPER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(tag):\n",
    "    return tag[2:]\n",
    "\n",
    "def get_spacy_ner_data(data):\n",
    "    result = []\n",
    "    # your code here\n",
    "\n",
    "    # your code here\n",
    "    return result\n",
    "\n",
    "# A test to make sure that your read_data function can handle a single \n",
    "# example with no entities\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"O\"),\n",
    "              (\"slept\",\"O\"),\n",
    "              (\".\",\"O\")]]\n",
    "assert(get_spacy_ner_data(test_data) == [('The dog slept .',{'entities':[]})])\n",
    "\n",
    "# You should write five additional tests here:\n",
    "# your code here\n",
    "\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now create the Danish SpaCy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .', {'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]})\n"
     ]
    }
   ],
   "source": [
    "danish_spacy_train = get_spacy_ner_data(danish_train)\n",
    "danish_spacy_dev = get_spacy_ner_data(danish_dev)\n",
    "danish_spacy_test = get_spacy_ner_data(danish_test)\n",
    "\n",
    "print(danish_spacy_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1.3: Evaluation for NER\n",
    "\n",
    "rubric={\"accuracy\":5}\n",
    "\n",
    "You'll now impement a function `evaluate` for computing the precision, recall and fscore of a NER model. The function takes two arguments: dataset with NE annotations from a NER model and another dataset with gold standard NE annotations. Both datasets are given in the return format of `get_spacy_ner_data`, i.e. each example in the dataset is is a pair like:\n",
    "\n",
    "```\n",
    "('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .', {'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]})\n",
    "```\n",
    "\n",
    "You should compute precision, recall and fscore over the entire dataset (i.e. you should **not** compute these separately for each example and then average them). Your function should return percentages, for example `67.5`.\n",
    "\n",
    "Before you start implementing the function, make sure that you understand the computation of precision, recall and fscore for the test case under the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sys_spacy_data,gold_spacy_data):\n",
    "    precision, recall, fscore = 0, 0, 0\n",
    "\n",
    "    # your code here\n",
    "\n",
    "    # your code here\n",
    "    \n",
    "    return precision, recall, fscore\n",
    "\n",
    "# This is a partial check that your evaluation works as it should. Please implement more tests\n",
    "# if you want to ensure yourself that the function works correctly.\n",
    "sys_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,5,\"PER\"),(12,17,\"LOC\")]}),\n",
    "            (\"word1 word2 word3 word4\",{\"entities\":[(6,11,\"ORG\")]})]\n",
    "\n",
    "gold_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,6,\"PER\"),(12,17,\"LOC\")]}),\n",
    "             (\"word1 word2 word3 word4\",{\"entities\":[]})]\n",
    "\n",
    "precision, recall, fscore = evaluate(sys_data,gold_data)\n",
    "assert(precision == 1.0/3 * 100)\n",
    "assert(recall    == 1.0/2 * 100)\n",
    "assert(fscore    == 2*1.0/3*1.0/2 / (1.0/3 + 1.0/2) * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Training a NER model on the Danish data\n",
    "\n",
    "Study the following [tutorial](https://spacy.io/usage/training#training-data) on training a NER model in spaCy. You will now initialize a NER model and train it on the Danish training data in spaCy format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.1: Initializing the NER model\n",
    "\n",
    "rubric={accuracy:5}\n",
    "\n",
    "The first step in training the NER model is to initialize it. Implement a function `init_model`. It takes two arguments: `spacy_train_data` a NE annotated dataset in spaCy format (as given by `get_spacy_ner_data`) and `language` a language code (either `da` or `en`). \n",
    "\n",
    "Check the [example code for the `main` function](https://github.com/explosion/spaCy/blob/v2.x/examples/training/train_ner.py) in the spaCy NER tutorial for more details on initializing the model. **For SpaCy version 2**, these instructions should work out of the box. **For SpaCy version 3**, you will need to make a small change:\n",
    "\n",
    "* Instead of calling `create_pipe()` and `get_pipe()` (SpaCy 2), simply call `add_pipe()` (SpaCy 3), which creates and returns the NER component.\n",
    "\n",
    "You should first create a blank `spacy.Language` text processing pipeline called `model` using `spacy.blank` and then add create and add a `\"ner\"` submodel to the model. You can use `nlp.create_pipe` and `nlp.add_pipe` here. Finally, you should add each entity type (for example, `ORG` and `PER`) to the ner model using `add_label`. Please implement this is a way which ensures that all entity types mentioned in `spacy_train_data` will be included in the model (even if there are more types than the ones included in our Danish NER data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.util import minibatch, compounding\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def init_model(spacy_train_data, language):\n",
    "    model = spacy.blank(language)\n",
    "\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    # your code here\n",
    "    # For SpaCy v2:\n",
    "    # model.create_pipe(\"ner\")\n",
    "    # ner = model.get_pipe(\"ner\")    \n",
    "\n",
    "\n",
    "    # `add_pipe` for \"ner\", https://spacy.io/api/language#add_pipe\n",
    "    # model.add_pipe(\"ner\", last=True)\n",
    "    # ner = model.get_pipe(\"ner\")    \n",
    "\n",
    "    # iterate training_data:\n",
    "    # {\"entities\":\n",
    "    #   [   (0,5,\"PER\"),                <--- `add_label(PER)`\n",
    "    #       (12,17,\"LOC\") ]}            <--- `add_label(LOC)`\n",
    "\n",
    "\n",
    "    # your code here\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "\n",
    "    # For SpaCy v2:\n",
    "    # model.disable_pipes(*other_pipes)\n",
    "    # optimizer = model.begin_training()\n",
    "    \n",
    "    model.select_pipes(disable=other_pipes)\n",
    "    optimizer = model.initialize()\n",
    "    \n",
    "    return model, optimizer\n",
    "\n",
    "danish_untrained_model, _ = init_model(danish_spacy_train,\"da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.2: Annotating the development set\n",
    "\n",
    "rubric={\"accuracy\":5}\n",
    "\n",
    "You should now implement a function `annotate` for annotating a dataset using your NER model. The function takes a dataset in spaCy format and a NER model as input and returns the annotated dataset in the same format.\n",
    "\n",
    "You can apply a model to an input sentence in the following way:\n",
    "\n",
    "```\n",
    "annotated = danish_model(\"Sue saw a dog .\")\n",
    "```\n",
    "\n",
    "`annotated` is a [spacy.tokens.Doc](https://v2.spacy.io/api/doc) object and `annotated.ents` is a tuple of entities each of which is a [`spacy.tokens.span.Span`](https://v2.spacy.io/api/span) object. (**HINT:** `Span.start_char`, `Span.end_char` and `Span.label_` might prove useful). For a dataset containing the example above, `annotate` function might return the list:\n",
    "\n",
    "```\n",
    "[(\"Sue saw a dog .\", {\"entities\":[(0,3,\"PER\")]})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(spacy_data, model):\n",
    "    result = []\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    # your code here\n",
    "    \n",
    "    return result\n",
    "\n",
    "# We're using an empty model which means that all annotations should be empty.\n",
    "# Note! Passing this assertion does not guarantee that your function works properly.\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_untrained_model)\n",
    "for sentence, annotations in danish_spacy_dev_sys:\n",
    "    assert(annotations == {\"entities\":[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.3 Training the NER model\n",
    "\n",
    "rubric={\"accuracy\":5}\n",
    "\n",
    "You should now implement the training function for a spaCy NER model. Check the [example code for the `main` function](https://github.com/explosion/spaCy/blob/v2.x/examples/training/train_ner.py) in the spaCy NER tutorial. **For SpaCy version 2**, these instructions should work out of the box. **For SpaCy version 3**, you will need to implement a small change:\n",
    "\n",
    "* Instead of giving a list of sentences and a list of annotations as parameters to `model.update()`, you should first compile each sentence and annotation into an Example object `Example.from_dict(sentence, annotation)`. You can then form a list of examples and give the list as input to `model.update()`. \n",
    "\n",
    "The skeleton code for `train` already initializes the NER model and an optimizer. It is your task to implement the training procedure for each epoch. At the start of the epoch, you should shuffle the training data `spacy_train_data`. Then you should split the data into batches using [`spacy.util.minibatch`](https://v2.spacy.io/api/top-level#util.minibatch). You can either use batches of fixed size (5) or use `spacy.util.compounding` here to generate batches of varying size. You should then call `model.update` on each batch following the example in the [main function in the tutorial](https://github.com/explosion/spaCy/blob/v2.x/examples/training/train_ner.py) using dropout `0.1`. You should also pass `losses` as a parameter to `model.update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from spacy.training import Example\n",
    "\n",
    "def train(spacy_train_data, spacy_dev_data, epochs,language):\n",
    "    # Initialize model and get optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "    \n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        \n",
    "        # your code here\n",
    "        # `shuffle` your training data:\n",
    "\n",
    "        # see https://stackoverflow.com/questions/56595714/training-ner-model-with-spacy-only-uses-one-core\n",
    "        # see https://stackoverflow.com/questions/66675261/how-can-i-work-with-example-for-nlp-update-problem-with-spacy3-0\n",
    "\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        # batches = list(minibatch(spacy_train_data, size=5))\n",
    "        # for each batch in numerate(batches):\n",
    "        # ...\n",
    "        #   example = []\n",
    "\n",
    "        # ...\n",
    "\n",
    "        # ```\n",
    "        # model.update(\n",
    "        #   example, losses, drop\n",
    "        # )\n",
    "        # ```\n",
    "\n",
    "        # your code here\n",
    "           \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a NER model on the Danish training data for 20 epochs. Take note of the best f-score on the development data during training. You should achieve f-score above 45%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 832.5588\n",
      "  PRECISION: 46.15%, RECALL: 5.19%, F-SCORE: 9.33%\n",
      "Loss for epoch 2: 174.1499\n",
      "  PRECISION: 43.46%, RECALL: 32.56%, F-SCORE: 37.23%\n",
      "Loss for epoch 3: 103.0850\n",
      "  PRECISION: 49.48%, RECALL: 41.50%, F-SCORE: 45.14%\n",
      "Loss for epoch 4: 79.4326\n",
      "  PRECISION: 43.01%, RECALL: 35.45%, F-SCORE: 38.86%\n",
      "Loss for epoch 5: 58.6696\n",
      "  PRECISION: 52.43%, RECALL: 43.52%, F-SCORE: 47.56%\n",
      "Loss for epoch 6: 34.0745\n",
      "  PRECISION: 46.85%, RECALL: 44.96%, F-SCORE: 45.88%\n",
      "Loss for epoch 7: 26.1795\n",
      "  PRECISION: 44.55%, RECALL: 40.06%, F-SCORE: 42.19%\n",
      "Loss for epoch 8: 23.6894\n",
      "  PRECISION: 46.45%, RECALL: 45.24%, F-SCORE: 45.84%\n",
      "Loss for epoch 9: 19.0971\n",
      "  PRECISION: 43.14%, RECALL: 44.38%, F-SCORE: 43.75%\n",
      "Loss for epoch 10: 16.9120\n",
      "  PRECISION: 49.01%, RECALL: 35.73%, F-SCORE: 41.33%\n",
      "Loss for epoch 11: 13.8621\n",
      "  PRECISION: 46.63%, RECALL: 43.80%, F-SCORE: 45.17%\n",
      "Loss for epoch 12: 7.7922\n",
      "  PRECISION: 47.48%, RECALL: 43.52%, F-SCORE: 45.41%\n",
      "Loss for epoch 13: 4.8169\n",
      "  PRECISION: 46.85%, RECALL: 44.96%, F-SCORE: 45.88%\n",
      "Loss for epoch 14: 7.1900\n",
      "  PRECISION: 49.04%, RECALL: 44.09%, F-SCORE: 46.43%\n",
      "Loss for epoch 15: 1.6909\n",
      "  PRECISION: 49.32%, RECALL: 42.07%, F-SCORE: 45.41%\n",
      "Loss for epoch 16: 3.5546\n",
      "  PRECISION: 44.16%, RECALL: 50.14%, F-SCORE: 46.96%\n",
      "Loss for epoch 17: 0.0002\n",
      "  PRECISION: 51.63%, RECALL: 45.53%, F-SCORE: 48.39%\n",
      "Loss for epoch 18: 0.0005\n",
      "  PRECISION: 50.16%, RECALL: 46.40%, F-SCORE: 48.20%\n",
      "Loss for epoch 19: 0.0000\n",
      "  PRECISION: 50.00%, RECALL: 46.11%, F-SCORE: 47.98%\n",
      "Loss for epoch 20: 0.0008\n",
      "  PRECISION: 48.62%, RECALL: 45.82%, F-SCORE: 47.18%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 48.62%, RECALL: 45.82%, F-SCORE: 47.18%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.4 Pocket learning  (optional)\n",
    "\n",
    "rubric={accuracy:3}\n",
    "\n",
    "During training, the performance of the model on the development set may fluctuate. If you just train for a fixed number of epochs like above, there is no guarantee that your final model will be your best one. You should re-write your training algorithm to [\"pocket\"](https://en.wikipedia.org/wiki/Perceptron#Variants) the best model so far. \n",
    "\n",
    "Your new `train` function should evaluate f-score on the development set after each epoch and return the model which attained the highest development accuracy. One way to accomplish this might be to write the model to disk whenever a new high score is attained and then read the best model from disk and return it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spacy_train_data, spacy_dev_data, epochs,language):\n",
    "    # Initialize model and get optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "    \n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    best_f = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        \n",
    "        # your code here\n",
    "        # training should be same as before (see 2.3)\n",
    "        # your code here\n",
    "           \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "        if f > best_f:\n",
    "            best_f = f\n",
    "            best_model = deepcopy(model)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please re-train the Danish model for 20 epochs. This should improve your f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "\n",
    "\n",
    "# PRECISION: 51.63%, RECALL: 45.53%, F-SCORE: 48.39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2.5 Adding pretrained bilingual embeddings\n",
    "\n",
    "rubric={\"accuracy\":3}\n",
    "\n",
    "We'll now initialize the model using pretrained bilingual Danish and English word embeddings. You should implement a new version of `init_model` which is identical to your previous implementation except that you load a pretrained embedding. You can do this using the member function `from_disk` of `model.vocab`. Check the [spaCy documentation](https://v2.spacy.io/api/vocab#from_disk) for further information. Load the embedding from `data/vocab`.\n",
    "\n",
    "**For SpaCy version 3**, it is not sufficient to simply call `from_disk()`, you will additionally need to give the argument `config={\"model\":{\"tok2vec\":{\"pretrained_vectors\":True}}}` when initializing the NER component of the model using `add_pipe()`. Otherwise, SpaCy will load the embeddings but won't actually use them (which results in lower F-score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.vocab import Vocab\n",
    "\n",
    "def init_model(spacy_train_data, language):\n",
    "    model = spacy.blank(language)#config={\"paths\":{\"vectors\":\"data/vocab\"}})\n",
    "\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    # `add_pipe` for \"ner\", https://spacy.io/api/language#add_pipe\n",
    "    # model.add_pipe(\"ner\", config={\"model\":{\"tok2vec\":{\"pretrained_vectors\":True}}}, last=True)\n",
    "    # ...\n",
    "    # your code here\n",
    "\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "    model.disable_pipes(*other_pipes)\n",
    "    optimizer = model.begin_training()\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a new model with pretrained embeddings on the Danish NER data. Take note of the best f-score on the development data during training. You should achieve f-score around 55%.\n",
    "\n",
    "Spacy may print a warning about renaming the embedding vectors. This is not a cause for concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 838.1308\n",
      "  PRECISION: 45.92%, RECALL: 12.97%, F-SCORE: 20.22%\n",
      "Loss for epoch 2: 155.7281\n",
      "  PRECISION: 50.16%, RECALL: 44.38%, F-SCORE: 47.09%\n",
      "Loss for epoch 3: 93.2945\n",
      "  PRECISION: 52.98%, RECALL: 46.11%, F-SCORE: 49.31%\n",
      "Loss for epoch 4: 113.7654\n",
      "  PRECISION: 50.26%, RECALL: 56.20%, F-SCORE: 53.06%\n",
      "Loss for epoch 5: 45.5698\n",
      "  PRECISION: 54.99%, RECALL: 58.79%, F-SCORE: 56.82%\n",
      "Loss for epoch 6: 35.9901\n",
      "  PRECISION: 58.14%, RECALL: 50.43%, F-SCORE: 54.01%\n",
      "Loss for epoch 7: 26.9974\n",
      "  PRECISION: 53.01%, RECALL: 53.31%, F-SCORE: 53.16%\n",
      "Loss for epoch 8: 16.4708\n",
      "  PRECISION: 56.62%, RECALL: 53.03%, F-SCORE: 54.76%\n",
      "Loss for epoch 9: 15.3483\n",
      "  PRECISION: 53.13%, RECALL: 51.30%, F-SCORE: 52.20%\n",
      "Loss for epoch 10: 11.9133\n",
      "  PRECISION: 55.46%, RECALL: 57.06%, F-SCORE: 56.25%\n",
      "Loss for epoch 11: 13.5871\n",
      "  PRECISION: 55.45%, RECALL: 51.30%, F-SCORE: 53.29%\n",
      "Loss for epoch 12: 8.1043\n",
      "  PRECISION: 57.72%, RECALL: 53.89%, F-SCORE: 55.74%\n",
      "Loss for epoch 13: 13.7993\n",
      "  PRECISION: 60.66%, RECALL: 53.31%, F-SCORE: 56.75%\n",
      "Loss for epoch 14: 3.2159\n",
      "  PRECISION: 57.81%, RECALL: 53.31%, F-SCORE: 55.47%\n",
      "Loss for epoch 15: 4.8196\n",
      "  PRECISION: 57.14%, RECALL: 51.87%, F-SCORE: 54.38%\n",
      "Loss for epoch 16: 1.8111\n",
      "  PRECISION: 58.76%, RECALL: 49.28%, F-SCORE: 53.61%\n",
      "Loss for epoch 17: 0.1312\n",
      "  PRECISION: 55.86%, RECALL: 52.16%, F-SCORE: 53.95%\n",
      "Loss for epoch 18: 0.0010\n",
      "  PRECISION: 54.83%, RECALL: 50.72%, F-SCORE: 52.69%\n",
      "Loss for epoch 19: 0.7145\n",
      "  PRECISION: 58.88%, RECALL: 51.59%, F-SCORE: 54.99%\n",
      "Loss for epoch 20: 0.0057\n",
      "  PRECISION: 57.01%, RECALL: 51.59%, F-SCORE: 54.16%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 57.01%, RECALL: 51.59%, F-SCORE: 54.16%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Training an English NER model and fine-tuning on Danish data\n",
    "\n",
    "Run the following code to train an English NER system on the [CoNLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf). This can take a while because the CoNLL dataset is far bigger than our Danish training data. Thats why we only train for 5 epochs.\n",
    "\n",
    "Note that F-score will be very high here because we're evaluating on English data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 11191.4381\n",
      "  PRECISION: 87.00%, RECALL: 86.03%, F-SCORE: 86.51%\n",
      "Loss for epoch 2: 5555.7599\n",
      "  PRECISION: 87.34%, RECALL: 87.65%, F-SCORE: 87.49%\n",
      "Loss for epoch 3: 4278.0694\n",
      "  PRECISION: 88.54%, RECALL: 87.80%, F-SCORE: 88.17%\n",
      "Loss for epoch 4: 3421.0851\n",
      "  PRECISION: 89.35%, RECALL: 88.49%, F-SCORE: 88.92%\n",
      "Loss for epoch 5: 3072.2541\n",
      "  PRECISION: 88.40%, RECALL: 88.46%, F-SCORE: 88.43%\n"
     ]
    }
   ],
   "source": [
    "english_train = read_data(open(path.join(\"data\",\"english-train.conll\")))\n",
    "english_dev = read_data(open(path.join(\"data\",\"english-dev.conll\")))\n",
    "\n",
    "english_spacy_train = get_spacy_ner_data(english_train)\n",
    "english_spacy_dev = get_spacy_ner_data(english_dev)\n",
    "\n",
    "english_model = train(english_spacy_train,english_spacy_dev,5,\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3.1: Fine-tuning the model on Danish data\n",
    "\n",
    "rubric={accuracy:3}\n",
    "\n",
    "You should now fine-tune the English NER model on the Danish training data. The function `retrain` below is very similar to the `train` function which you implemented earlier but `retrain` does not initialize the NER model. Instead it takes the model as parameter and continues training it. \n",
    "\n",
    "You only need to copy yor code from `train` and then you are ready to fine-tune the model. After fine-tuning, the model f-score should be around 60%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 199.5989\n",
      "  PRECISION: 56.16%, RECALL: 53.89%, F-SCORE: 55.00%\n",
      "Loss for epoch 2: 83.7119\n",
      "  PRECISION: 59.48%, RECALL: 59.65%, F-SCORE: 59.57%\n",
      "Loss for epoch 3: 25.3469\n",
      "  PRECISION: 64.74%, RECALL: 58.21%, F-SCORE: 61.31%\n",
      "Loss for epoch 4: 7.9118\n",
      "  PRECISION: 63.20%, RECALL: 61.38%, F-SCORE: 62.28%\n",
      "Loss for epoch 5: 3.0076\n",
      "  PRECISION: 64.48%, RECALL: 62.25%, F-SCORE: 63.34%\n",
      "Loss for epoch 6: 0.6200\n",
      "  PRECISION: 62.29%, RECALL: 62.82%, F-SCORE: 62.55%\n",
      "Loss for epoch 7: 1.3127\n",
      "  PRECISION: 62.72%, RECALL: 61.10%, F-SCORE: 61.90%\n",
      "Loss for epoch 8: 0.0002\n",
      "  PRECISION: 62.80%, RECALL: 60.81%, F-SCORE: 61.79%\n",
      "Loss for epoch 9: 0.0001\n",
      "  PRECISION: 63.10%, RECALL: 61.10%, F-SCORE: 62.08%\n",
      "Loss for epoch 10: 0.0003\n",
      "  PRECISION: 62.24%, RECALL: 60.81%, F-SCORE: 61.52%\n",
      "Loss for epoch 11: 0.0000\n",
      "  PRECISION: 62.43%, RECALL: 60.81%, F-SCORE: 61.61%\n",
      "Loss for epoch 12: 0.0000\n",
      "  PRECISION: 62.83%, RECALL: 61.38%, F-SCORE: 62.10%\n",
      "Loss for epoch 13: 0.0010\n",
      "  PRECISION: 63.13%, RECALL: 61.67%, F-SCORE: 62.39%\n",
      "Loss for epoch 14: 0.0000\n",
      "  PRECISION: 63.69%, RECALL: 61.67%, F-SCORE: 62.66%\n",
      "Loss for epoch 15: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n",
      "Loss for epoch 16: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n",
      "Loss for epoch 17: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n",
      "Loss for epoch 18: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n",
      "Loss for epoch 19: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n",
      "Loss for epoch 20: 0.0000\n",
      "  PRECISION: 63.58%, RECALL: 61.38%, F-SCORE: 62.46%\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def retrain(spacy_train_data, spacy_dev_data, epochs,model,pretrained_fn):\n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    model = deepcopy(model)\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        \n",
    "        # your code here\n",
    "\n",
    "        # your code here\n",
    "        \n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model\n",
    "\n",
    "transfer_model = retrain(danish_spacy_train, danish_spacy_dev, 20,english_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, apply your the basic NER model and the transfer model on the Danish test data. Your f-score should be around 55% for the basic model and around 60% for the transfer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating basic Danish model on test set:\n",
      "  PRECISION: 60.23%, RECALL: 52.82%, F-SCORE: 56.28%\n",
      "\n",
      "Evaluating basic transfer model on test set:\n",
      "  PRECISION: 62.83%, RECALL: 61.54%, F-SCORE: 62.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating basic Danish model on test set:\")\n",
    "danish_spacy_test_sys_basic = annotate(danish_spacy_test, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_basic,danish_spacy_test)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "print()\n",
    "\n",
    "print(\"Evaluating basic transfer model on test set:\")\n",
    "danish_spacy_test_sys_transfer = annotate(danish_spacy_test, transfer_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_transfer,danish_spacy_test)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3.2 Analyzing the results (optional)\n",
    "\n",
    "rubric={\"reasoning\":3}\n",
    "\n",
    "Investigate `danish_spacy_test_sys_basic` and `danish_spacy_test_sys_transfer` to figure out why the transfer model delivers better results then the basic NER model. You can approach the question in different ways. You might look at things like:\n",
    "\n",
    "* Does the transfer model get better at identifying names which are similar in the Danish and English NER data?\n",
    "* Does the transfer model identify more purely Danish names which are not found by the basic model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
