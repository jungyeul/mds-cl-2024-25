{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33d3b32",
   "metadata": {},
   "source": [
    "# DSCI 563 Lab Assignment 2: Hidden Markov Model Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b368b6",
   "metadata": {},
   "source": [
    "The problem of **sequence labeling** consists of  \n",
    "\n",
    "- part-of-speech tagging (POS tagging), \n",
    "- chunking, \n",
    "- named entity recognition (NER), and \n",
    "- semantic role labeling (SRL) \n",
    "\n",
    "in which we use any sequence labeling algorithms (such as HMM) to train and evaluate data sets. \n",
    "\n",
    "| *The*| *luxury*| *auto* | *maker* | *last* | *year*| *sold*  | *1,214*  | *cars*  | *in*  | *the* |*U.S.*  |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| dt |nn |nn |nn |jj |nn |vbd |cd |nns |in |dt |nnp |\n",
    "|b-np |i-np |i-np |i-np |o |o |o |b-np |i-np |o |b-np |i-np |\n",
    "| o|o|o|o|o|o|o|o|o|o|o|loc|\n",
    "| b-ar$_0$| i-ar$_0$| i-ar$_0$| i-ar$_0$| o| o| pred| b-ar$_1$| i-ar$_1$| o| o| o|\n",
    "\n",
    "\n",
    "| | dataset | train |dev| test |\n",
    "|---|---|---|---|---|\n",
    "|POS tagging | WSJ | Section 0-18 |  Section 19-21 | Section 22-34 |\n",
    "|Chunking |WSJ |Section 15-18 | - | Section 20 |\n",
    "|NER | Reuters| eng.train |eng.testa | eng.testb |\n",
    "|SRL | WSJ| Section 2-21  | Section 24   | Section 23   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3af99a",
   "metadata": {},
   "source": [
    "## Assignment Objectives\n",
    "\n",
    "In this assignment you will\n",
    "- Build a Hidden Markov Model\n",
    "- Use Hard EM to do semi-supervised part of speech tagging\n",
    "\n",
    "In Part 1, you see the `HMM` class which we will use for this lab. Parts 1-2 ask you to fill in methods in the class and Part 3 asks you to apply the class for semi-supervised POS tagging of the Brown corpus. \n",
    "\n",
    "Parts 2 and 3 depend on the first part which implements training for HMMs, but they do not depend on each other.\n",
    "\n",
    "Part 3 uses inference for the HMM class. You should start developing a solution using the provided greedy inference algorithm but switch to Viterbi, when Part 2 has been completed.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Run the code below to access relevant modules (you can add to this as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a15884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import defaultdict,Counter\n",
    "from random import shuffle,seed,choice,random\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f82ac",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:2}\n",
    "\n",
    "- You have been assigned a team for this project, which you will find in the teams.txt file on the DSCI 563 course repo\n",
    "- One person in each group should create a private UBC github repo, and give access to all group members as well as the members of the teaching team\n",
    "- In the `README.md` in the individual lab repo (the one created when the lab is opened) for all members of the group, you should have a link to this private, shared repo. Pushing that link is your only \"submission\". Don't put anything else in your repo for this lab.\n",
    "- In the private shared repo, include the final notebook which contains the work by all team members. \n",
    "- **Note** any commits to the private shared repo after the deadline will result in a late penalty being applied to the project, so be careful about that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4fc0866",
   "metadata": {},
   "source": [
    "### Part 1: HMM Initialization and training\n",
    "\n",
    "#### Assignment 1.1\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Your first task is to initialize an HMM model in the function `HMM.__init__()`, which takes two arguments a vocabulary `emissions` and a state set `states`. The `HMM` class contains the members\n",
    "\n",
    "* `self.emissions`, the list of word types, and\n",
    "* `self.states`, the list of possible POS tags.\n",
    "* `self.w2i` and `self.i2w`, dictionaries for converting between word tokens like `\"dog\"` and index numbers like 134.\n",
    "* `self.s2i` and `self.i2s`, dictionaries for converting between states like `\"NOUN\"` and index numbers like 12.\n",
    "\n",
    "You should initialize three member variables:\n",
    "\n",
    "* `self.init_prob`, an `np.array` of initial state probabilities of shape `1 x size_of_state_set`.\n",
    "* `self.emission_prob`, an `np.array` of emission probabilities of shape `size_of_state_set x size_of_vocabulary`. \n",
    "* `self.transition_prob` an `np.array` of transition probabilities of shape `size_of_state_set x size_of_state_set`.\n",
    "\n",
    "All array values should be initialized to 0.\n",
    "\n",
    "After you complete this assignment correctly, you should be able to pass the assertions for 1.1 below the HMM class definition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbb7dd",
   "metadata": {},
   "source": [
    "#### Assignment 1.2\n",
    "rubric={accuracy:3, quality:1}\n",
    "\n",
    "Your next task is fully supervised training of the HMM model in the function `HMM.train()`. The function takes a training set `data`, which is a list of tagged sentences, e.g.:\n",
    "```\n",
    "[[(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")], [(\"the\",\"DET\"),(\"dog\",\"NOUN\")]]\n",
    "```\n",
    "\n",
    "**Before you do anything else, please initialize all initial, emission and transition probabilities to 0.**\n",
    "\n",
    "You should then convert words and POS tags in `data` into index numbers using the function `HMM.data2i()`. The output will look something like this: \n",
    "\n",
    "```\n",
    "[[(101, 10), (1000, 5), (5, 2)], [(101, 10), (1000, 5)]]\n",
    "```\n",
    "\n",
    "The left element of each pair is an index number corresponding to a word type in the vocabulary and the right element is an index number of a state (i.e. POS tag in our case).\n",
    "\n",
    "Start the actual training by storing **counts** of emissions, transitions and initial states in `self.emission_prob`, `self.transition_prob` and `self.initial_prob`, respectively. For example, if the word number `101` is emitted twice in the state `10`, then we want `self.emission_prob[10][101] == 2`. Similarly, if we transition from state `10` to state `5` twice in `data`, we want `self.transition_prob[10][5] == 2`.\n",
    "\n",
    "Then **apply add-one smoothing** to all counts, and normalize probabilities according to:\n",
    "\n",
    "$$\\large P_{initial}(s) = \\frac{{\\rm count}_{initial}(s)}{\\sum_{t} {\\rm count}_{initial}(t)}$$\n",
    "\n",
    "$$\\large P_{emission}(w | s) = \\frac{{\\rm count}(w,s)}{{\\rm count}(s)}$$\n",
    "\n",
    "$$\\large P_{transition}(t|s) = \\frac{{\\rm count}(s,t)}{{\\rm count}(s)}$$\n",
    "\n",
    "Finally, convert all probabilities to log-probabilities using $p \\mapsto \\log_2 p$ (note that the base of the logarithm is 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c05434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Symbol used to replace unknown tokens in the input \n",
    "UNK=\"<UNK>\"\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, emissions, states):\n",
    "            # Vocabulary and tag set.\n",
    "            self.emissions = deepcopy(emissions + [UNK])\n",
    "            self.states = deepcopy(states)\n",
    "\n",
    "            # Use these to convert between strings and ID numbers\n",
    "            self.w2i = {w:i for i, w in enumerate(self.emissions)}\n",
    "            self.i2w = self.emissions\n",
    "            self.s2i = {s:i for i,s in enumerate(self.states)}\n",
    "            self.i2s = self.states\n",
    "        \n",
    "            # your code here\n",
    "\n",
    "            \n",
    "    def data2i(self, data):\n",
    "        \"\"\" Encode emissions and states into index numbers. \n",
    "        \n",
    "            ex is either a sequence of words or a sequence \n",
    "            of word-state pairs.\n",
    "        \"\"\"\n",
    "        idx_data = []\n",
    "        if type(data[0][0]) == type(\"\"):\n",
    "            for ex in data:\n",
    "                idx_data.append([])\n",
    "                for w in ex:\n",
    "                    w = w if w in self.w2i else UNK\n",
    "                    idx_data[-1].append(self.w2i[w])\n",
    "        else:\n",
    "            for ex in data:\n",
    "                idx_data.append([])\n",
    "                for w,s in ex:\n",
    "                    w = w if w in self.w2i else UNK\n",
    "                    idx_data[-1].append((self.w2i[w], self.s2i[s]))\n",
    "        return idx_data\n",
    "\n",
    "    def train(self, data):\n",
    "        # Initialize all parameters to 0.\n",
    "        self.init_prob[:] = 0\n",
    "        self.emission_prob[:] = 0\n",
    "        self.transition_prob[:] = 0\n",
    "        \n",
    "        data = self.data2i(data)\n",
    "        # your code here\n",
    "   \n",
    "\n",
    "    def greedy_decode(self, ex):\n",
    "        \"\"\" Greedy (or beam 1 decoding). \"\"\"\n",
    "        ex = self.data2i([ex])[0]\n",
    "        state_distr = np.array(self.init_prob)\n",
    "        output = []\n",
    "        log_prob = 0\n",
    "        for w in ex:  \n",
    "            state_distr += self.emission_prob[:, w].reshape(1,-1)\n",
    "            output.append(state_distr.argmax())\n",
    "            log_prob = state_distr.max()\n",
    "            state_distr = log_prob + self.transition_prob[[output[-1]], :]\n",
    "        return [(self.i2w[w], self.i2s[s]) for w, s in zip(ex, output)], log_prob\n",
    "    \n",
    "    def extract_output(self, trellis, back_pointers, ex):\n",
    "        log_prob = trellis[:,-1].max()\n",
    "        output = [trellis[:,-1].argmax()]\n",
    "        while len(output) < len(ex):\n",
    "            output.append(back_pointers[output[-1], len(ex) - len(output)])\n",
    "        output = output[::-1]\n",
    "        \n",
    "        return [(self.i2w[w], self.i2s[s]) for w, s in zip(ex, output)], log_prob\n",
    "    \n",
    "    def viterbi_decode(self, ex):\n",
    "        \"\"\" Viterbi decoding using loops. \"\"\"\n",
    "        # your code here\n",
    "\n",
    "    \n",
    "    def fast_viterbi_decode(self, ex):\n",
    "        \"\"\" Vectorized Viterbi decoding. \"\"\"\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbba1b8",
   "metadata": {},
   "source": [
    "Assertions to check your code for Assignment 1.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08992328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_prob\n",
      "[[0. 0. 0. 0.]]\n",
      "transition_prob\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "emission_prob\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM([\"the\", \"dog\", \"barks\"],[\"DET\", \"NOUN\", \"VERB\", \"ADJ\"])\n",
    "assert hmm.init_prob.shape == (1,4)                 # 1 x size_of_state_set (4)\n",
    "assert hmm.transition_prob.shape == (4,4)           # size_of_state_set x size_of_vocabulary (3+UNK)\n",
    "assert hmm.emission_prob.shape == (4,4)             # size_of_state_set x size_of_state_set\n",
    "print(\"Success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da32989e",
   "metadata": {},
   "source": [
    "Assertions to check your code for Assignment 1.2:\n",
    "`hmm = HMM([\"the\", \"dog\", \"barks\"],[\"DET\", \"NOUN\", \"VERB\", \"ADJ\"])`\n",
    " self.emission_prob, self.transition_prob]:\n",
    "\n",
    "\n",
    "`inin_prob`: \n",
    "- before laplace smoothing: `[2/2, 0/2, 0/2, 0/2]`\n",
    "- after  laplace smoothing: `[2+1/2+4, 0+1/2+4, 0+1/2+4, 0+1/2+4]` where `4` is # of T\n",
    "\n",
    "`emission_prob` for `the`, `dog`, `barks`, `UNK`:\n",
    "- before laplace smoothing: `[[2/2 0/2 0/2 0/2] [0/2 2/2 0/2 0/2] [0/1 0/1 1/1 0/1] [0. 0. 0. 0.]]`\n",
    "- after  laplace smoothing: `[[2+1/2+4, 0+1/2+4, 0+1/2+4, 0+1/2+4] [0+1/2+4, 2+1/2+4, 0+1/2+4, 0+1/2+4] [0+1/1+4, 0+1/1+4, 1+1/1+4, 0+1/1+4] [0+1/4, 0+1/4, 0+1/4, 0+1/4]]`\n",
    "\n",
    "`trainsition_prob` for `\"DET\", \"NOUN\", \"VERB\", \"ADJ\"` where `DET->NOUN:2` and `NOUN->VERB:1`:\n",
    "- before laplace smoothing: `[[0. 2. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 0.] [0. 0. 0. 0.]]`\n",
    "- +1                      : `[[1. 3. 1. 1.] [1. 1. 2. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]]`\n",
    "- after laplace smoothing : `[[1./sum(axis=1) 3./6 1./6 1./6] [1./sum(axis=1) 1./5 2./5 1./5] ...] `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa297ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_prob\n",
      "[[-1.        -2.5849625 -2.5849625 -2.5849625]]\n",
      "transition_prob\n",
      "[[-2.5849625  -1.         -2.5849625  -2.5849625 ]\n",
      " [-2.32192809 -2.32192809 -1.32192809 -2.32192809]\n",
      " [-2.         -2.         -2.         -2.        ]\n",
      " [-2.         -2.         -2.         -2.        ]]\n",
      "emission_prob\n",
      "[[-1.         -2.5849625  -2.5849625  -2.5849625 ]\n",
      " [-2.5849625  -1.         -2.5849625  -2.5849625 ]\n",
      " [-2.32192809 -2.32192809 -1.32192809 -2.32192809]\n",
      " [-2.         -2.         -2.         -2.        ]]\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "data = [[(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")], [(\"the\",\"DET\"),(\"dog\",\"NOUN\")]]\n",
    "hmm.train(data)\n",
    "\n",
    "assert np.abs(np.exp2(hmm.init_prob) - [3/6, 1/6, 1/6, 1/6]).sum() < 0.001\n",
    "assert np.abs(np.exp2(hmm.emission_prob) - [[3/6, 1/6, 1/6, 1/6],[1/6, 3/6, 1/6, 1/6],[1/5, 1/5, 2/5, 1/5], [1/4, 1/4, 1/4, 1/4]]).sum() < 0.001\n",
    "assert np.abs(np.exp2(hmm.transition_prob) - [[1/6, 3/6, 1/6, 1/6], [1/5, 1/5, 2/5, 1/5], [1/4, 1/4, 1/4, 1/4], [1/4, 1/4, 1/4, 1/4]]).sum() < 0.001\n",
    "\n",
    "output, prob = hmm.greedy_decode(\"the dog barks\".split())\n",
    "assert output == [(\"the\", \"DET\"), (\"dog\", \"NOUN\"), (\"barks\", \"VERB\")]\n",
    "assert np.abs(prob - np.log2(3/6 * 3/6 * 3/6 * 3/6 * 2/5 * 2/5)).sum() < 0.0001\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf24694",
   "metadata": {},
   "source": [
    "`init_prob`\n",
    "```\n",
    " [\"DET\",     \"NOUN\",    \"VERB\",    \"ADJ\"]  \n",
    "[[-1.        -2.5849625 -2.5849625 -2.5849625]]\n",
    "```\n",
    "$P(D|bos) = -1$, $P(V|bos) = -2.5849625$, ...\n",
    "\n",
    "\n",
    "`transition_prob`\n",
    "```\n",
    "         \"DET\"       \"NOUN\"      \"VERB\"      \"ADJ\"\n",
    "\"DET\"  [[-2.5849625  -1.         -2.5849625  -2.5849625 ]\n",
    "\"NOUN\"  [-2.32192809 -2.32192809 -1.32192809 -2.32192809]\n",
    "\"VERB\"  [-2.         -2.         -2.         -2.        ]\n",
    "\"ADJ\"   [-2.         -2.         -2.         -2.        ]]\n",
    "```\n",
    "$P(N|D) = -1$, $P(V|N) = -1.32192809$, ...\n",
    "\n",
    "`emission_prob`\n",
    "```\n",
    "         \"the\"       \"dog\"       \"barks\"     \"UNK\"\n",
    "\"DET\"  [[-1.         -2.5849625  -2.5849625  -2.5849625 ]\n",
    "\"NOUN\"  [-2.5849625  -1.         -2.5849625  -2.5849625 ]\n",
    "\"VERB\"  [-2.32192809 -2.32192809 -1.32192809 -2.32192809]\n",
    "\"ADJ\"   [-2.         -2.         -2.         -2.        ]]\n",
    "```\n",
    "$P(the|D) = -1$, $P(dog|N) = -1$, ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50780f18",
   "metadata": {},
   "source": [
    "### Part 2: Viterbi decoding\n",
    "\n",
    "In this part, you'll implement Viterbi decoding in two ways. \n",
    "\n",
    "**Note!** Assignments 2.1 and 2.2 do not depent on each other. You can work on them in parallel. \n",
    "\n",
    "#### Assignment 2.1\n",
    "rubric={accuracy:4,quality:2}\n",
    "\n",
    "In this assignment, you will implement the Viterbi algorithm using loops (i.e. as a non-vectorized algorithm) in the function `HMM.viterbi_decode()`.\n",
    "\n",
    "The function takes a single argument `ex`, a list representing a sentence, e.g.:\n",
    "```\n",
    "[\"The\", \"dog\", \"sleeps\"]\n",
    "```\n",
    "\n",
    "Start by converting `ex` into a list of index numbers using the function `HMM.data2i()`. Note that the function takes a list of sentences as input instead of a single sentence. \n",
    "\n",
    "You should then initialize two `np.array` objects: \n",
    "\n",
    "* `trellis`, which contains the Viterbi probabilities $v_i(s)$ for each state $s$ and position $i$ in the sentence, and \n",
    "* `back_pointers`, which contains back pointers. These identify the optimal tag history.\n",
    "\n",
    "Both of these need to have dimension `len(self.states) x len(ex)` and you should initialize all values in `trellis` to negative infinity (`-float(\"inf\")`) and all values in `back_pointers` to `-1`.\n",
    "\n",
    "We can then start filling the trellis one row at a time:\n",
    "\n",
    "1. We'll first initialize all elements `trellis[0,s]` to the sum of the initial log-probability of state `s` and the emission log-probability of the first input word `ex[0]` in the given state.\n",
    "2. When filling in the cell for state `s` in position `i+1`, we need to loop over all states in row `i` and find the state $r_{max}$ which maximizes $\\log_2 v_{i}(r) + \\log_2 P_{transition}(r,s) + \\log_2 P_{emission}(w,s)$, where $w$ is the $i+1$th token in `ex`. This is the Viterbi log-probability $v_{i+i}(s)$.\n",
    "3. You should also store $r_{argmax}$ in cell `s,i+1` in `back_pointers`.\n",
    "\n",
    "When you've filled in `trellis` and `back_pointers`, call the function `self.extract_output()` which will extract the output tag sequence.\n",
    "\n",
    "After successfully completing the Viterbi algorithm, you should be able to pass the following assertions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db3e08",
   "metadata": {},
   "source": [
    "![HMM overview](hmm-overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f06ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM([\"the\", \"dog\", \"barks\"],[\"DET\", \"NOUN\", \"VERB\", \"ADJ\"])\n",
    "\n",
    "data = [[(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")], [(\"the\",\"DET\"),(\"dog\",\"NOUN\")]]\n",
    "hmm.train(data)\n",
    "\n",
    "output, prob = hmm.viterbi_decode(\"the dog barks\".split())\n",
    "assert(output == [(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")])\n",
    "assert np.abs(prob - np.log2(3/6 * 3/6 * 3/6 * 3/6 * 2/5 * 2/5)).sum() < 0.0001\n",
    "print(\"Success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25fa36c8",
   "metadata": {},
   "source": [
    "#### Assignment 2.2\n",
    "rubric={accuracy:4,quality:2,efficiency:3}\n",
    "\n",
    "You will now implement a vectorized version of Viterbi in the function `HMM.fast_viterbi_decode()`, which again takes a single argument: `ex` representing a sentence. A successfully implemented vectorized Viterbit can be substantially faster than a loop-based approach.\n",
    "\n",
    "Start by converting word tokens in `ex` into index numbers and intialize `trellis` and `back_pointers` as in Assignment 2.1.\n",
    "\n",
    "You should then initialize the first row of the trellis to the sum of your initial probability vector and emission probabilities for `ex[0]`. Note that for full efficieny marks, you have to compute all the probabilities using a single addition of `np.arrays`.\n",
    "\n",
    "When filling in row `i+1`, You should start by computing a `len(self.states) x len(self.states)` matrix `log_probs`, where the element `log_probs[r,s]` represents the log-probability: \n",
    "\n",
    "$\\log_2 v_{i}(r) + \\log_2 P_{transition}(r,s) + \\log_2 P_{emission}(w,s)$\n",
    "\n",
    "where $w$ is the token `ex[i+1]`. For full efficiency marks, you should compute this matrix using a single addition of `np.array` objects. Specifically, you'll need to use the previous row of the trellis `trellis[:,i]`, the transition log-probabilities `self.transition_prob` and the emission probabilites for $w$. \n",
    "\n",
    "After you've computed `log_probs`, you need to find the maximal element in each row and assign it to row `i+1` in `trellis`. These will be your Viterbi log-probabilities `v_{i+1}(s)` in row `i+1`. You also need to store the index of the element in `back_pointers`. For full efficieny marks you should use a NumPy operation to fill in your trellis row and a single operation to fill in the back pointers. \n",
    "\n",
    "When you've completed the entire `trellis` and `back_pointers`, call the function `self.extract_output` which will extract the output tag sequence.\n",
    "\n",
    "**Note!** You need to ensure that [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) works correctly when summing arrays. Your transition log-probabilities will be an `n x n` matrix and your trellis row and emission log-probabilities will be either `1 x n` or `n x 1` arrays. Both shapes can be broadcast to `n x n` but this will lead to different results as demonstrated by the following example of NumPy addition:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "3 & 4\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "5 & 6\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "3 & 4\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "5 & 6 \\\\\n",
    "5 & 6 \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "6 & {\\color{red} 8}\\\\\n",
    "{\\color{red} 8} & 10\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "vs.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "3 & 4\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "5\\\\\n",
    "6\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "3 & 4\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "5 & 5\\\\\n",
    "6 & 6\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "6 & {\\color{red}7}\\\\\n",
    "{\\color{red}9} & 10\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "    \n",
    "Make sure that you know how broadcasting should happen and use <code>numpy.array.reshape</code> to transpose axes if needed.\n",
    "</div>\n",
    "\n",
    "After successfully completing the vectorized Viterbi algorithm, you should be able to pass the following assertions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58ced61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM([\"the\", \"dog\", \"barks\"],[\"DET\", \"NOUN\", \"VERB\", \"ADJ\"])\n",
    "\n",
    "data = [[(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")], [(\"the\",\"DET\"),(\"dog\",\"NOUN\")]]\n",
    "hmm.train(data)\n",
    "\n",
    "output, prob = hmm.fast_viterbi_decode(\"the dog barks\".split())\n",
    "assert(output == [(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")])\n",
    "assert np.abs(prob - np.log2(3/6 * 3/6 * 3/6 * 3/6 * 2/5 * 2/5)) < 0.0001\n",
    "print(\"Success!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a964dc2b",
   "metadata": {},
   "source": [
    "### Part 3: Hard EM\n",
    "\n",
    "In this part, you will use hard EM to train an HMM in a semi-supervised manner. We'll use the Brown corpus and form a small manually annotated training set which is combined with a large amount of unlabeled data.\n",
    "\n",
    "\n",
    "The `accuracy` function below computes tagging accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14145c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(sys_data, gold_data):\n",
    "    \"\"\" Compute tagging accuracy. \"\"\"\n",
    "    sys_tags = [t for ex in sys_data for w,t in ex]\n",
    "    gold_tags = [t for ex in gold_data for w,t in ex]\n",
    "    return 100 * (np.array(sys_tags) == np.array(gold_tags)).sum()/len(gold_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fb09b",
   "metadata": {},
   "source": [
    "#### Assignment 3.1\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Start by reading the tagged sentences in the Brown corpus using the tag set `\"universal\"`. You should then divide the corpus into a train split `train_set`, containing 80% of the sentences in the corpus, and a test split `test_set` containing the remaining 20%.\n",
    "\n",
    "To avoid over-representation of any domain in the training and test set, you should assign sentences into the train and test splits evenly over the entire corpus. For every consecutive 10 sentences in the Brown corpus, assign 8 to `train_set` and the remaining 2 to `test_set`. E.g. if the sentences in the Brown corpus are $s_1 ... s_n$, then the test set will contain sentences $s_9, s_{10}, s_{19}, s_{20}, s_{29}, s_{30}, ...$ and all remaining sentences will end up in `train_set`. \n",
    "\n",
    "You should also generate `train_input` and `test_input` which contain untagged versions of the sentences in `train_set` and `test_set`, i.e. simply lists of word tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6881def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2d3b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len. train_input =  45872\n",
      "len. test_input =  11468\n"
     ]
    }
   ],
   "source": [
    "print(\"len. train_input = \", len(train_input))\n",
    "print(\"len. test_input = \", len(test_input))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bebb73bf",
   "metadata": {},
   "source": [
    "#### Assignment 3.2\n",
    "rubric={accuracy:1}\n",
    "\n",
    "We will now generate a small labeled training set `mini_train_set`. Sample every 5000th sentence from `train_set` into the small labeled training set.\n",
    "\n",
    "You should also generate \n",
    "\n",
    "    `vocab`, a list of word types occurring in `train_set` and `test_set`, as well as \n",
    "    `tags`, a list of unique tags occurring in `mini_train_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f810682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate at which we sample examples from our large \n",
    "# training set into our small annotated training set\n",
    "INV_TRAIN_SAMPLING_RATE=5000\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca76e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len. mini_train_set =  10\n",
      "len. vocab =  49815\n",
      "len, tags =  11\n"
     ]
    }
   ],
   "source": [
    "print(\"len. mini_train_set = \", len(mini_train_set))\n",
    "print(\"len. vocab = \", len(vocab))\n",
    "print(\"len, tags = \", len(tags))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a812e21c",
   "metadata": {},
   "source": [
    "#### Assignment 3.3\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Initialize an `HMM` object `hmm` using the vocabulary and tagset from Assignment 1.2. Train the model on `mini_train_set`.\n",
    "\n",
    "Apply inference to the sentences in `test_input` and print tagging accuracy. Initially, you can use `HMM.greedy_decode` (you should get accuracy around 30%). Switch to `HMM.fast_viterbi_decode` when it is ready (you should get accuracy close to 50%).\n",
    "\n",
    "This is out baseline accuracy before we run hard EM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29c7478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging accuracy on test set: 49.20%\n"
     ]
    }
   ],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8736bc",
   "metadata": {},
   "source": [
    "#### Assignment 3.4\n",
    "rubric={accuracy:2}\n",
    "\n",
    "When we run hard EM, we will use tag perplexity as stopping criterio. You should now implement the function `get_perplexity` which takes a list $\\mathcal{D}$ of $N$ tagged sentences $(x_i, y_i)$ and log-probabilities $\\log_2 P(x_i, y_i)$ as input. It then returns average per-token tag perplexity as defined by the following formula:\n",
    "\n",
    "$$\\large {\\rm PP}(\\mathcal{D}) = 2^{- \\frac{1}{N} \\cdot \\sum_{i=1}^N \\log_2 \\big( \\frac{P(x_i,y_i)}{|x_i|}\\big)}$$\n",
    "\n",
    "where $|x_i|$ is the length of sentence $x_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4040d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity(data):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab131fb8",
   "metadata": {},
   "source": [
    "Assertion to check your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb4623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1115.9061629064486"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [([(\"the\", \"DET\"),(\"dog\", \"NOUN\"),(\"barks\",\"VERB\")], -35.853), \n",
    "        ([(\"the\",\"DET\"),(\"dog\",\"NOUN\")], -16.594)]\n",
    "assert np.abs(get_perplexity(data) - 1115.9062) < 0.001\n",
    "print(\"Success!\")\n",
    "get_perplexity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115fb7b",
   "metadata": {},
   "source": [
    "#### Assignment 3.5\n",
    "rubric={accuracy:3,quality:1}\n",
    "\n",
    "Finally, we will implement hard EM. Her you will alternate between:\n",
    "\n",
    "* the **E-step** where you tag both `train_input` and `test_input` using current HMM parameters, and\n",
    "* the **M-step** where you retrain the HMM using the tagged output from the E-step.\n",
    "\n",
    "We'll use perplexity as stopping criterion. Generally the M-step will always reduce perplexity. When this reduction `delta` is smaller than a threshold `PERPLEXITY_TH` (0.1), we will stop the EM algorithm. Start by initializing two variables `old_perplexity` and `delta` (i.e. the change in perplexity) to infinity (`float(\"inf\")`). Also reinitialize an `HMM` object `hmm` using `vocab` and `tags`, and train it on `mini_train_set`.\n",
    "\n",
    "At every step of the algorithm, you should first tag the entire training set `train_input` and the test set `test_input` using your current parameters for `hmm` (use `HMM.fast_viterbi_decode()` if it's available, or `HMM.greedy_decode()`, otherwise). \n",
    "\n",
    "You should then compute `perplexity` on the tagged output. Using your old and new perplexity value, compute an updated value for `delta`. Your should also print the current `perplexity` and `delta`. \n",
    "\n",
    "If `delta` is less than `PERPLEXITY_TH`, you can stop. Otherwise, use the tagger output for `train_input` and `test_input` to retrain `hmm`.\n",
    "\n",
    "The perplexity should continuously drop  when using Viterbi, i.e. the perplexity should always be positive (note that this is not necessarily true for `HMM.greedy_decode()`). The output of your code should look somewhat like this (exact numbers may vary):\n",
    "\n",
    "```\n",
    "Perplexity 93187.23582920311, Delta inf\n",
    "Perplexity 1139.9238338813068, Delta 92047.31199532181\n",
    "Perplexity 1091.1388085910141, Delta 48.78502529029265\n",
    "Perplexity 1070.2039949884722, Delta 20.934813602541908\n",
    "Perplexity 1058.0225338763507, Delta 12.181461112121497\n",
    "Perplexity 1046.6394965626928, Delta 11.383037313657951\n",
    "Perplexity 1038.5689868317825, Delta 8.070509730910317\n",
    "Perplexity 1031.4118994196706, Delta 7.157087412111878\n",
    "...\n",
    "```\n",
    "\n",
    "Note, it will take a while to run EM. Using `HMM.fast_viterbi_decode` will be much faster than using `HMM.viterbi_decode`. If you need to, you can increase `PERPLEXITY_TH` (maybe set the value to `10`) and the algorithm will run for fewer iterations, however, then your improvements in tagging accuracy will also be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19e75fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity 93187.23582920311, Delta inf\n",
      "Perplexity 1138.5166673205285, Delta 92048.71916188259\n",
      "Perplexity 1090.714779722392, Delta 47.801887598136545\n",
      "Perplexity 1070.4186072568796, Delta 20.296172465512427\n",
      "Perplexity 1058.3564657661252, Delta 12.062141490754357\n",
      "Perplexity 1046.70582331659, Delta 11.650642449535098\n",
      "Perplexity 1038.5945742586457, Delta 8.111249057944406\n",
      "Perplexity 1031.4303413596956, Delta 7.164232898950104\n",
      "Perplexity 1025.611318659956, Delta 5.819022699739662\n",
      "Perplexity 1020.3892310824843, Delta 5.222087577471598\n",
      "Perplexity 1015.9301294775604, Delta 4.459101604923944\n",
      "Perplexity 1012.3090026168911, Delta 3.6211268606692784\n",
      "Perplexity 1009.4388950559606, Delta 2.870107560930478\n",
      "Perplexity 1007.3941124301826, Delta 2.044782625777998\n",
      "Perplexity 1005.692491205116, Delta 1.701621225066674\n",
      "Perplexity 1004.5079769338549, Delta 1.1845142712610368\n",
      "Perplexity 1003.4261644342002, Delta 1.0818124996546885\n",
      "Perplexity 1002.8497844898543, Delta 0.5763799443459448\n",
      "Perplexity 1002.276679670208, Delta 0.5731048196463462\n",
      "Perplexity 1001.7730202355739, Delta 0.5036594346340735\n",
      "Perplexity 1001.3745722249997, Delta 0.3984480105741568\n",
      "Perplexity 1001.0467194503642, Delta 0.32785277463551665\n",
      "Perplexity 1000.7101928711521, Delta 0.33652657921209084\n",
      "Perplexity 1000.3646577347639, Delta 0.3455351363882073\n",
      "Perplexity 999.863771864585, Delta 0.5008858701788768\n",
      "Perplexity 998.9518825841355, Delta 0.9118892804494863\n",
      "Perplexity 997.5516292951721, Delta 1.4002532889634267\n",
      "Perplexity 996.2481342677396, Delta 1.3034950274325183\n",
      "Perplexity 994.7467028811856, Delta 1.5014313865540316\n",
      "Perplexity 993.1677592372463, Delta 1.578943643939283\n",
      "Perplexity 991.5350080829918, Delta 1.6327511542544926\n",
      "Perplexity 990.1447689651146, Delta 1.3902391178771722\n",
      "Perplexity 989.1118551139634, Delta 1.0329138511511928\n",
      "Perplexity 988.3808359833431, Delta 0.7310191306203251\n",
      "Perplexity 987.7830551855928, Delta 0.5977807977502607\n",
      "Perplexity 987.3327324774871, Delta 0.450322708105773\n",
      "Perplexity 987.0568661643434, Delta 0.27586631314363785\n",
      "Perplexity 986.8496505174119, Delta 0.2072156469315587\n",
      "Perplexity 986.7068487641799, Delta 0.14280175323199273\n",
      "Perplexity 986.6048676786951, Delta 0.10198108548479468\n",
      "Perplexity 986.5001587523726, Delta 0.10470892632247342\n",
      "Perplexity 986.3285454346503, Delta 0.17161331772229005\n",
      "Perplexity 986.2278577285075, Delta 0.1006877061428213\n",
      "Perplexity 986.1508651069727, Delta 0.07699262153482778\n"
     ]
    }
   ],
   "source": [
    "PERPLEXITY_TH = 0.1\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7240cf",
   "metadata": {},
   "source": [
    "Finally, tag `test_input` using your EM-trained `hmm` and evaluate accuracy. If you used Viterbi for decoding, you should get at least a few percentage points improvement in tagging accuracy (accuracy at least 52%). When using greedy decoding, results may actually be a bit worse than without hard EM training, so make sure to run your final results using Viterbi. \n",
    "\n",
    "Using soft EM, we could get larger improvements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf33fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.61697411852475\n"
     ]
    }
   ],
   "source": [
    "# your code here for fast_viterbi_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f62f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.61697411852475\n"
     ]
    }
   ],
   "source": [
    "# your code here for viterbi_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55733e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.10324396771213\n"
     ]
    }
   ],
   "source": [
    "# your code here for greedy_decode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1bbd221",
   "metadata": {},
   "source": [
    "Johnson, M. (2007). Why Doesn’t EM Find Good HMM POS-Taggers? *Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)*, 296–305. http://www.aclweb.org/anthology/D/D07/D07-1031"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab8a52",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "20bf69066c0dd38d51965b69d5e1b6e387082e3198ba56e97997ac55f4e50ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
