{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colx 525 Lab Assignment 3: POS Tagging\n",
    "\n",
    "## Assignment objectives\n",
    "\n",
    "In this assignment, you will develop a POS tagger using pytorch. You will:\n",
    "\n",
    "1. Read in training, development and test data using `torchtext`.\n",
    "1. Implement a baseline majority class tagger.\n",
    "1. Numericalize data (i.e. transform sentences and words into `torch.Tensor` objects).\n",
    "1. Develop a BiLSTM POS tagger.  \n",
    "\n",
    "The [`pytorch` documentation](https://pytorch.org/docs/stable/index.html) will be useful in this lab.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "You will need to install the Python modules `torchtext`, `torch` and `numpy`. The easiest way to do this is using `anaconda` or `pip`.\n",
    "\n",
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}\n",
    "\n",
    "To get the marks for tidy submission:\n",
    "\n",
    "* Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "* Be sure to follow the general lab instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Reading in data\n",
    "\n",
    "We will now read in training development and test sets using the `torchtext` library which `torchtext` can simplify your data handling code. Please have a look at [Practical lecture 5-6].\n",
    "\n",
    "Before you do anything else, please download the following file, place it in your `Lab3` directory and unzip it:\n",
    "\n",
    "```\n",
    "https://mpsilfve.github.io/assets/uddata.zip\n",
    "```\n",
    "\n",
    "We'll start by installing the `conllu` library which can read data Universal Dependencies treebank data. We'll also read the English UD training, development and test set from the `uddata` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://mpsilfve.github.io/assets/uddata.zip\n",
    "# !unzip uddata.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import os\n",
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def read_data(dire, lang):\n",
    "    # 1K sentences (*.head) instead of the entire train file (12K)\n",
    "    train_data = conllu.parse(open(os.path.join(dire, f\"{lang}-ud-train.conllu.head\")).read())     \n",
    "    dev_data = conllu.parse(open(os.path.join(dire, f\"{lang}-ud-dev.conllu\")).read())\n",
    "    test_data = conllu.parse(open(os.path.join(dire, f\"{lang}-ud-test.conllu\")).read())\n",
    "    return train_data, dev_data, test_data\n",
    "\n",
    "train_data, dev_data, test_data = read_data(\"uddata\",\"en\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the format of the UD data. We'll print the first three tokens in the first training sentence. As you can see, the token is represented by a dictionary with several fields. For our purposes, the most important ones are:\n",
    "\n",
    "* `form` which gives the word form, and\n",
    "* `upos` which gives the Universal Dependencies POS tag. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# newdoc id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000\n",
    "# sent_id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0001\n",
    "# text = Al-Zaman : American forces killed Shaikh Abdullah al-Ani, the preacher at the mosque in the town of Qaim, near the Syrian border.\n",
    "1       Al      Al      PROPN   NNP     Number=Sing     0       root    _       SpaceAfter=No\n",
    "2       -       -       PUNCT   HYPH    _       1       punct   _       SpaceAfter=No\n",
    "3       Zaman   Zaman   PROPN   NNP     Number=Sing     1       flat    _       _\n",
    "4       :       :       PUNCT   :       _       1       punct   _       _\n",
    "5       American        american        ADJ     JJ      Degree=Pos      6       amod    _       _\n",
    "6       forces  force   NOUN    NNS     Number=Plur     7       nsubj   _       _\n",
    "7       killed  kill    VERB    VBD     Mood=Ind|Tense=Past|VerbForm=Fin        1       parataxis       _       _\n",
    "8       Shaikh  Shaikh  PROPN   NNP     Number=Sing     7       obj     _       _\n",
    "9       Abdullah        Abdullah        PROPN   NNP     Number=Sing     8       flat    _       _\n",
    "10      al      al      PROPN   NNP     Number=Sing     8       flat    _       SpaceAfter=No\n",
    "11      -       -       PUNCT   HYPH    _       8       punct   _       SpaceAfter=No\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'form': 'Al',\n",
       "  'lemma': 'Al',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': {'Number': 'Sing'},\n",
       "  'head': 0,\n",
       "  'deprel': 'root',\n",
       "  'deps': None,\n",
       "  'misc': {'SpaceAfter': 'No'}},\n",
       " {'id': 2,\n",
       "  'form': '-',\n",
       "  'lemma': '-',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': 'HYPH',\n",
       "  'feats': None,\n",
       "  'head': 1,\n",
       "  'deprel': 'punct',\n",
       "  'deps': None,\n",
       "  'misc': {'SpaceAfter': 'No'}},\n",
       " {'id': 3,\n",
       "  'form': 'Zaman',\n",
       "  'lemma': 'Zaman',\n",
       "  'upos': 'PROPN',\n",
       "  'xpos': 'NNP',\n",
       "  'feats': {'Number': 'Sing'},\n",
       "  'head': 1,\n",
       "  'deprel': 'flat',\n",
       "  'deps': None,\n",
       "  'misc': None}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "train_data[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Following the example in [`practical_lecture5`](https://github.ubc.ca/MDS-CL-2022-23/COLX_525_morphology_students/blob/master/lectures/practical_lecture5.ipynb) and this [tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class) implement a `UDDataset` class. It should be a subclass of `torch.utils.data.Dataset`.\n",
    "\n",
    "Your `__init__` function should take a dataset (`train_data`, `dev_data` or `test_data`) as argument. and assign it as `self.data`. You'll also need to define `__len__` and `__getitem__` member functions which return the length of `self.data` and and element at index `i` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ## from practical_lecture5:\n",
    "# class PandasDataset(Dataset):\n",
    "#     def __init__(self, dataframe):\n",
    "#         self.dataframe = dataframe\n",
    "#         self.iloc = dataframe.iloc        \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.dataframe.iloc[index]\n",
    "\n",
    "# Your code here\n",
    "class UDDataset(Dataset):\n",
    "    # Your `__init__` function should take a dataset (`train_data`, `dev_data` or `test_data`) as argument. \n",
    "    # and assign it as `self.data`. \n",
    "    def __init__(self, data):\n",
    "    \n",
    "\n",
    "    # You'll define `__len__` \n",
    "    # which return the length of `self.data` \n",
    "    def __len__(self):\n",
    "\n",
    "    \n",
    "    # and define `__getitem__` \n",
    "    # which return the element (`data`) at index `i`\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "\n",
    "\n",
    "train = UDDataset(train_data)\n",
    "dev = UDDataset(dev_data)\n",
    "test = UDDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'conllu.models.SentenceList'>\n",
      "<class '__main__.UDDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(train[0][:3] == train_data[0][:3])\n",
    "print(type(train_data))\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "rubric={accuracy:5}\n",
    "\n",
    "We'll now compile three vocabularies. One for words, one for characters and one for POS tags. Let's start by initializing generators for words (`yield_tokens`), characters (`yield_chars`) and POS tags (`yield_pos`). These extract words, characters and POS tags from a batch of examples. \n",
    "\n",
    "Note, that:\n",
    "* `yield_tokens` generates a list of tokens: `[\"the\", \"dog\", \"sleeps\"]`\n",
    "* `yield_chars` generates a list of characters: `[\"t\", \"h\", \"e\", \"d\", \"o\", \"g\", \"s\", \"l\", \"e\", \"e\", \"p\", \"s\"]` (notice the lack of spaces between words)\n",
    "* `yield_pos` generates a list of POS tags: `[\"DET\",\"NOUN\",\"VERB\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.']\n",
      "Characters: ['A', 'l', '-', 'Z', 'a', 'm', 'a', 'n', ':', 'A', 'm', 'e', 'r', 'i', 'c', 'a', 'n', 'f', 'o', 'r', 'c', 'e', 's', 'k', 'i', 'l', 'l', 'e', 'd', 'S', 'h', 'a', 'i', 'k', 'h', 'A', 'b', 'd', 'u', 'l', 'l', 'a', 'h', 'a', 'l', '-', 'A', 'n', 'i', ',', 't', 'h', 'e', 'p', 'r', 'e', 'a', 'c', 'h', 'e', 'r', 'a', 't', 't', 'h', 'e', 'm', 'o', 's', 'q', 'u', 'e', 'i', 'n', 't', 'h', 'e', 't', 'o', 'w', 'n', 'o', 'f', 'Q', 'a', 'i', 'm', ',', 'n', 'e', 'a', 'r', 't', 'h', 'e', 'S', 'y', 'r', 'i', 'a', 'n', 'b', 'o', 'r', 'd', 'e', 'r', '.']\n",
      "POS: ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# provided code\n",
    "def yield_tokens(data):\n",
    "    for ex in data:\n",
    "        yield([tok[\"form\"] for tok in ex])\n",
    "        \n",
    "def yield_chars(data):\n",
    "    for ex in data:\n",
    "        yield([c for tok in ex for c in tok[\"form\"]])\n",
    "        \n",
    "def yield_pos(data):\n",
    "    for ex in data:\n",
    "        yield([tok[\"upos\"] for tok in ex])\n",
    "\n",
    "# print(\"First training example:\")\n",
    "print(\"Tokens:\", next(yield_tokens(train)))\n",
    "print(\"Characters:\", next(yield_chars(train)))\n",
    "print(\"POS:\", next(yield_pos(train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example in [`practical_lecture5`](https://github.ubc.ca/MDS-CL-2022-23/COLX_525_morphology_students/blob/master/lectures/practical_lecture5.ipynb), use `build_vocab_from_iterator` and the **training set** to define:\n",
    "\n",
    "* a word vocabulary `word_vocab` based on the tokens generated by `yield_tokens`. Your vocabulary should contain the special symbols: \\<unk\\>, \\<start\\> and \\<end\\>\n",
    "* a character vocabulary `char_vocab` based on the tokens generated by `yield_chars`. Your vocabulary should contain the special symbols: \\<unk\\>, \\<start\\>, \\<end\\> and \\<pad\\>\n",
    "* a pos vocabulary `pos_vocab` based on the tokens generated by `yield_pos`. Your vocabulary should contain the special symbol: \\<unk\\>\n",
    "\n",
    "**Hint:** Remember to call `set_default_index` to set the ID for the \\<unk\\> token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## from practical_lecture5:\n",
    "# token_vocab = build_vocab_from_iterator(yield_tokens(train_data, tokenizer),\n",
    "#                                         specials=[\"<unk>\", \"<start>\", \"<end>\", \"<pad>\"])\n",
    "# token_vocab.set_default_index(token_vocab[\"<unk>\"])\n",
    "\n",
    "# label_vocab = build_vocab_from_iterator(yield_labels(train_data), specials=[\"<unk>\"])\n",
    "# label_vocab.set_default_index(label_vocab[\"<unk>\"])\n",
    "\n",
    "\n",
    "# Your code here\n",
    "# Note that your word, charcter, pos DO NOT requires the `tokenizer` \n",
    "\n",
    "# `word_vocab` based on the tokens generated by `yield_tokens`. \n",
    "# it should contain the special symbols: <unk>, <start> and <end>\n",
    "# `set_default_index` for <unk> to avoid index errors.\n",
    "word_vocab = \n",
    "\n",
    "# `char_vocab` based on the tokens generated by `yield_chars`. \n",
    "# it should contain the special symbols: <unk>, <start>, <end> and <pad>\n",
    "# `set_default_index` for <unk> to avoid index errors.\n",
    "char_vocab = \n",
    "\n",
    "# `pos_vocab` based on the tokens generated by `yield_pos`. \n",
    "# it should contain the special symbol: <unk> (See `label_vocab` in practical_lecture5)\n",
    "# `set_default_index` for <unk> to avoid index errors.\n",
    "pos_vocab = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "rubric={accuracy:10}\n",
    "\n",
    "We'll now write a `collate_batch` function which numericalizes a batch of examples into torch tensors.\n",
    "\n",
    "We'll use the following transformation functions which tokenize and numericalize the tokens, characters and POS tags, respectively. Note that both `word_transform` and `char_transform` add \\<start\\> and \\<end\\> tokens to the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided code:\n",
    "word_transform = lambda s: [word_vocab[w] for w in [\"<start>\"] + s + [\"<end>\"]]\n",
    "char_transform = lambda w: [char_vocab[c] for c in [\"<start>\"] + w + [\"<end>\"]]\n",
    "pos_transform = lambda s: [pos_vocab[w] for w in s]\n",
    "\n",
    "# `data_process` from seq2seq_tutorial: \n",
    "# [trg_vocab[token] for token in spacy_en_tokenizer(trg_raw.lower())]\n",
    "# [src_vocab[token] for token in spacy_fr_tokenizer(src_raw.lower())]\n",
    "# --> then, they go to `torch.tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "190\n",
      "forces\n"
     ]
    }
   ],
   "source": [
    "print(word_vocab['forces'])\n",
    "print(word_vocab.get_stoi()['forces'])\n",
    "print(word_vocab.get_itos()[190])\n",
    "\n",
    "# ---\n",
    "# print(word_vocab['Al'])\n",
    "# print(word_vocab.get_stoi()['Al'])\n",
    "# print(word_vocab.get_itos()[61])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `collate_batch` takes a batch of examples as input. It extracts the tokens, characters and POS tags for each example using `yield_tokens`, `yield_chars` and `yield_pos`, respectively.\n",
    "\n",
    "Your first task to use `word_transform` and `pos_transform` to transform token and POS lists into torch tensors (with data type `torch.long`). You should store the tensors as `token_tensor` and `pos_tensor`. `token_tensor` should have size `sentence_length + 2 x 1` and `pos_tensor` will have size `sentence_length x 1`. The `+ 2` comes from adding start and end symbols to `tokens`. \n",
    "\n",
    "**Hint:** You may need to call the torch function [`unsqueeze`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze) to ensure the correct size.\n",
    "\n",
    "Your second task is to convert `chars` into a list of tensors of shape `1 x word_length`. Remember that `yield_chars` returns a long list containing all the characters in the input sentence. You should first split this up into a list contining inidividual words like `[\"t\", \"h\", \"e\"]` using the function `split_char_sequence`. Store the result as `chars`.\n",
    "\n",
    "You can then use `char_transform` to numericalize each word in `chars`. Again, store the resulting list as `chars`. Finally, compile each numericalized word in `chars` into a torch tensor with dtype `torch.long`. Store the result as `char_tensor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided code:\n",
    "\n",
    "from itertools import islice\n",
    "from collections import namedtuple\n",
    "\n",
    "Example = namedtuple(\"Example\",[\"word\", \"pos\", \"char\"])\n",
    "\n",
    "def split_char_sequence(chars, tokens):\n",
    "    \"\"\" Split a sequence of characters representing a sentence into \n",
    "        sequences representing the individual words in the sentence\n",
    "        \n",
    "        FROM    : [\"t\",\"h\",\"e\",\"d\",\"o\",\"g\",\"s\",\"l\",\"e\",\"e\",\"p\",\"s\"] \n",
    "        TO      : [[\"t\",\"h\",\"e\"], [\"d\",\"o\",\"g\"], [\"s\",\"l\",\"e\",\"e\",\"p\",\"s\"]]\n",
    "        \n",
    "        Arguments:        \n",
    "        chars: A list of chars [\"t\",\"h\",\"e\",\"d\",\"o\",\"g\",\"s\",\"l\",\"e\",\"e\",\"p\",\"s\"]\n",
    "        tokens: A list of tokens [\"the\", \"dog\", \"sleeps\"]\n",
    "    \"\"\"\n",
    "    word_lens = [len(w) for w in tokens]\n",
    "    chars = iter(chars)\n",
    "    return [list(islice(chars, elem)) for elem in word_lens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['t', 'h', 'e'], ['d', 'o', 'g'], ['s', 'l', 'e', 'e', 'p', 's']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "\n",
    "# # Basic example\n",
    "# >>> Point = namedtuple('Point', ['x', 'y'])\n",
    "# >>> p = Point(11, y=22)     # instantiate with positional or keyword arguments\n",
    "# >>> p[0] + p[1]             # indexable like the plain tuple (11, 22)\n",
    "# 33\n",
    "# >>> x, y = p                # unpack like a regular tuple\n",
    "# >>> x, y\n",
    "# (11, 22)\n",
    "# >>> p.x + p.y               # fields also accessible by name\n",
    "# 33\n",
    "# >>> p                       # readable __repr__ with a name=value style\n",
    "# Point(x=11, y=22)\n",
    "\n",
    "split_char_sequence([\"t\",\"h\",\"e\",\"d\",\"o\",\"g\",\"s\",\"l\",\"e\",\"e\",\"p\",\"s\"], [\"the\", \"dog\", \"sleeps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## from practical_lecture5:\n",
    "# # Build batches. Each example contains a list of tokens and a gold standard label.\n",
    "# def collate_batch(batch):\n",
    "#     label_list, text_list = [], []\n",
    "#     for quote, person in zip(yield_tokens(batch, tokenizer), yield_labels(batch)):\n",
    "#         label_list.append(label_transform(person))\n",
    "#         processed_text = torch.tensor(text_transform(quote))\n",
    "#         text_list.append(processed_text)\n",
    "\n",
    "#     # We use pad_sequence to pad all examples in the batch to the same length using the padding token <pad>    \n",
    "#     return (pad_sequence(text_list, padding_value=token_vocab[\"<pad>\"], batch_first=True), \n",
    "#                          torch.tensor(label_list))\n",
    "\n",
    "def collate_batch(batch):\n",
    "    pos_list, token_list, char_list, word_lens = [], [], [], []         # we don't use word_lens (ignore it);\n",
    "    for tokens, chars, pos in zip(yield_tokens(batch), \n",
    "                                  yield_chars(batch),\n",
    "                                  yield_pos(batch)):\n",
    "        # Your code here\n",
    "        # >> token and pos should be \"tensor\" using `word_transform and pos_transform`;\n",
    "        # >> char should be tensor using `char_transform` after using given `split_char_sequence`; \n",
    "                \n",
    "\n",
    "                \n",
    "        # Please make sure not to change the indentation\n",
    "        # of the following three lines\n",
    "        token_list.append(token_tensor)\n",
    "        pos_list.append(pos_tensor)\n",
    "        char_list += char_tensors\n",
    "\n",
    "    return Example(token_list[0],\n",
    "                   pos_list[0],\n",
    "                   (pad_sequence(char_list, batch_first=True, padding_value=char_vocab[\"<pad>\"]).unsqueeze(0),\n",
    "                    len(token_list[0])-2,\n",
    "                    [len(w) for w in tokens]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://i.stack.imgur.com/NiJu4.png](https://i.stack.imgur.com/NiJu4.png)\n",
    "\n",
    "https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TokenList<Al, -, Zaman, :, American, forces, killed, Shaikh, Abdullah, al, -, Ani, ,, the, preacher, at, the, mosque, in, the, town, of, Qaim, ,, near, the, Syrian, border, ., metadata={newdoc id: \"weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000\", sent_id: \"weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000-0001\", text: \"Al-Zaman : American forces killed Shaikh Abdullah al-Ani, the preacher at the mosque in the town of Qaim, near the Syrian border.\"}>]\n",
      "-------------------------------\n",
      "tokens>\t ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.']\n",
      "after word_tranform>\t [1, 61, 12, 921, 38, 240, 190, 287, 908, 2115, 112, 12, 2136, 4, 3, 4048, 44, 3, 3857, 9, 3, 1173, 6, 1380, 4, 611, 3, 1410, 323, 5, 2]\n",
      "after tensor>\t tensor([   1,   61,   12,  921,   38,  240,  190,  287,  908, 2115,  112,   12,\n",
      "        2136,    4,    3, 4048,   44,    3, 3857,    9,    3, 1173,    6, 1380,\n",
      "           4,  611,    3, 1410,  323,    5,    2])\n",
      "unsqueeze>\t tensor([[   1],\n",
      "        [  61],\n",
      "        [  12],\n",
      "        [ 921],\n",
      "        [  38],\n",
      "        [ 240],\n",
      "        [ 190],\n",
      "        [ 287],\n",
      "        [ 908],\n",
      "        [2115],\n",
      "        [ 112],\n",
      "        [  12],\n",
      "        [2136],\n",
      "        [   4],\n",
      "        [   3],\n",
      "        [4048],\n",
      "        [  44],\n",
      "        [   3],\n",
      "        [3857],\n",
      "        [   9],\n",
      "        [   3],\n",
      "        [1173],\n",
      "        [   6],\n",
      "        [1380],\n",
      "        [   4],\n",
      "        [ 611],\n",
      "        [   3],\n",
      "        [1410],\n",
      "        [ 323],\n",
      "        [   5],\n",
      "        [   2]])\n",
      "-------------------------------\n",
      "Example(word=tensor([[   1],\n",
      "        [  61],\n",
      "        [  12],\n",
      "        [ 921],\n",
      "        [  38],\n",
      "        [ 240],\n",
      "        [ 190],\n",
      "        [ 287],\n",
      "        [ 908],\n",
      "        [2115],\n",
      "        [ 112],\n",
      "        [  12],\n",
      "        [2136],\n",
      "        [   4],\n",
      "        [   3],\n",
      "        [4048],\n",
      "        [  44],\n",
      "        [   3],\n",
      "        [3857],\n",
      "        [   9],\n",
      "        [   3],\n",
      "        [1173],\n",
      "        [   6],\n",
      "        [1380],\n",
      "        [   4],\n",
      "        [ 611],\n",
      "        [   3],\n",
      "        [1410],\n",
      "        [ 323],\n",
      "        [   5],\n",
      "        [   2]]), pos=tensor([[3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [7],\n",
      "        [1],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2],\n",
      "        [6],\n",
      "        [1],\n",
      "        [4],\n",
      "        [6],\n",
      "        [1],\n",
      "        [4],\n",
      "        [6],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2],\n",
      "        [4],\n",
      "        [6],\n",
      "        [7],\n",
      "        [1],\n",
      "        [2]]), char=(tensor([[[ 1, 29, 13,  2,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 32,  2,  3,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 81,  5, 17,  5,  7,  2,  3,  3,  3],\n",
      "         [ 1, 54,  2,  3,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 29, 17,  4, 11,  8, 16,  5,  7,  2],\n",
      "         [ 1, 18,  9, 11, 16,  4, 10,  2,  3,  3],\n",
      "         [ 1, 27,  8, 13, 13,  4, 14,  2,  3,  3],\n",
      "         [ 1, 31, 12,  5,  8, 27, 12,  2,  3,  3],\n",
      "         [ 1, 29, 23, 14, 15, 13, 13,  5, 12,  2],\n",
      "         [ 1,  5, 13,  2,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 32,  2,  3,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 29,  7,  8,  2,  3,  3,  3,  3,  3],\n",
      "         [ 1, 26,  2,  3,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1,  6, 12,  4,  2,  3,  3,  3,  3,  3],\n",
      "         [ 1, 22, 11,  4,  5, 16, 12,  4, 11,  2],\n",
      "         [ 1,  5,  6,  2,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1,  6, 12,  4,  2,  3,  3,  3,  3,  3],\n",
      "         [ 1, 17,  9, 10, 43, 15,  4,  2,  3,  3],\n",
      "         [ 1,  8,  7,  2,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1,  6, 12,  4,  2,  3,  3,  3,  3,  3],\n",
      "         [ 1,  6,  9, 20,  7,  2,  3,  3,  3,  3],\n",
      "         [ 1,  9, 18,  2,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1, 74,  5,  8, 17,  2,  3,  3,  3,  3],\n",
      "         [ 1, 26,  2,  3,  3,  3,  3,  3,  3,  3],\n",
      "         [ 1,  7,  4,  5, 11,  2,  3,  3,  3,  3],\n",
      "         [ 1,  6, 12,  4,  2,  3,  3,  3,  3,  3],\n",
      "         [ 1, 31, 21, 11,  8,  5,  7,  2,  3,  3],\n",
      "         [ 1, 23,  9, 11, 14,  4, 11,  2,  3,  3],\n",
      "         [ 1, 24,  2,  3,  3,  3,  3,  3,  3,  3]]]), 29, [2, 1, 5, 1, 8, 6, 6, 6, 8, 2, 1, 3, 1, 3, 8, 2, 3, 6, 2, 3, 4, 2, 4, 1, 4, 3, 6, 6, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:1])\n",
    "print(\"-------------------------------\")\n",
    "b = collate_batch(train_data[0:1])\n",
    "print(\"-------------------------------\")\n",
    "print(b)\n",
    "\n",
    "\n",
    "# Some assertions to check your code\n",
    "# b = collate_batch(dev_data[0:1])\n",
    "# assert(b.word.size()[0] == len(dev_data[0]) + 2)\n",
    "# assert(b.pos.size()[0] == len(dev_data[0]))\n",
    "# chars, _, _ = b.char\n",
    "# assert(chars.size()[2] == len(dev_data[0]))\n",
    "# assert(chars.size()[1] == max([len(tok[\"form\"]) for tok in dev_data[0]]) + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then use the function to numericalize the training, development and test data. Note, that we set `shuffle=True` for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided code:\n",
    "dev_iter = DataLoader(dev_data, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
    "train_iter = DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then take a closer look at the training examples retured in our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', 'From', 'the', '<unk>', 'comes', 'this', 'story', ':', '<end>']\n",
      "ex.word is a tensor containing the word tokens in the sentence:\n",
      "tensor([[   1],\n",
      "        [ 670],\n",
      "        [   3],\n",
      "        [   0],\n",
      "        [1532],\n",
      "        [  36],\n",
      "        [ 350],\n",
      "        [  38],\n",
      "        [   2]])\n",
      "It has size sentence_length+2 x 1:\n",
      "torch.Size([9, 1])\n",
      "\n",
      "ex.pos is a tensor containing the POS tags in the sentence:\n",
      "tensor([[4],\n",
      "        [6],\n",
      "        [3],\n",
      "        [5],\n",
      "        [6],\n",
      "        [1],\n",
      "        [2]])\n",
      "It has size sentence_length x 1:\n",
      "torch.Size([7, 1])\n",
      "\n",
      "ex.char is a tuple having three elements:\n",
      "char_tensor contains character-sequence representations of the tokens in the sentence\n",
      "tensor([[[ 1, 60, 11,  9, 17,  2,  3],\n",
      "         [ 1,  6, 12,  4,  2,  3,  3],\n",
      "         [ 1, 29, 37,  2,  3,  3,  3],\n",
      "         [ 1, 16,  9, 17,  4, 10,  2],\n",
      "         [ 1,  6, 12,  8, 10,  2,  3],\n",
      "         [ 1, 10,  6,  9, 11, 21,  2],\n",
      "         [ 1, 54,  2,  3,  3,  3,  3]]])\n",
      "It has size 1 x sentence_length x sequence_length:\n",
      "torch.Size([1, 7, 7])\n",
      "\n",
      "sentence_length simply gives the sentence_length (without <start> and <end> tokens):\n",
      "7\n",
      "\n",
      "word_lengths contains the length of each word in the sentence (without <start> and <end> tokens):\n",
      "[4, 3, 2, 5, 4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "ex = next(iter(dev_iter))\n",
    "\n",
    "print(\"ex.word is a tensor containing the word tokens in the sentence:\")\n",
    "print(ex.word)\n",
    "print(\"It has size sentence_length+2 x 1:\")\n",
    "print(ex.word.size())\n",
    "print()\n",
    "print(\"ex.pos is a tensor containing the POS tags in the sentence:\")\n",
    "print(ex.pos)\n",
    "print(\"It has size sentence_length x 1:\")\n",
    "print(ex.pos.size())\n",
    "print()\n",
    "print(\"ex.char is a tuple having three elements:\")\n",
    "char_tensor, sentence_length, word_lengths = ex.char\n",
    "print(\"char_tensor contains character-sequence representations of the tokens in the sentence\")\n",
    "print(char_tensor)\n",
    "print(\"It has size 1 x sentence_length x sequence_length:\")\n",
    "print(char_tensor.size())\n",
    "print()\n",
    "print(\"sentence_length simply gives the sentence_length (without <start> and <end> tokens):\")\n",
    "print(sentence_length)\n",
    "print()\n",
    "print(\"word_lengths contains the length of each word in the sentence (without <start> and <end> tokens):\")\n",
    "print(word_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Simple baseline tagger\n",
    "\n",
    "To be able to gauge the performance of our deep learning tagger, we'll now implement a baseline majority label classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Counting tags\n",
    "\n",
    "rubric={accuracy:5}\n",
    "\n",
    "As a first step, you will count the occurrences of different POS tags for each word in the **training data**. These counts will be stored in `tag_counts` below. For exaple, `tag_counts[\"this\"][\"PRON\"]` should tell you how many times the word \"this\" was tagged `PRON` in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# A counter for POS tags. tag_counts[wf][pos] should denote the number of times we saw the word wf with \n",
    "# POS tag pos in the training data.\n",
    "tag_counts = defaultdict(Counter)\n",
    "\n",
    "# Populate tag_counts with the counts of different POS tags for each word type in the training data. \n",
    "# your code here\n",
    "# >> \n",
    "\n",
    "\n",
    "# A few assertions to make sure that your code is working properly.\n",
    "assert(tag_counts[\"this\"][\"DET\"] == 46)\n",
    "assert(tag_counts[\"this\"][\"PRON\"] == 20)\n",
    "assert(tag_counts[\"this\"][\"ADV\"] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.2 Tagging the development data\n",
    "\n",
    "rubric={accuracy:5}\n",
    "\n",
    "The next step is to tag the development data. For each example in the development set, you should append a list of predicted POS tags to `output_tags`. \n",
    "\n",
    "For each word in an example, output its most common tag given by `tag_counts`. For OOV (out-of-vocabulary) words which are missing from `tag_counts`, you can predict `NOUN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tags = []\n",
    "word_itos = word_vocab.get_itos()\n",
    "\n",
    "for ex in dev_iter:\n",
    "    output_tags.append([])\n",
    "    for wf in ex.word[1:-1]:\n",
    "        wf = word_itos[wf]\n",
    "        # your code here\n",
    "        # >> predicted POS tags to `output_tags`        \n",
    "        # >> for OOV, predict NOUN\n",
    "\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `accuracy` function below, you can now print the baseline tagging accuracy on the development set. It should be around 77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for baseline majority class tagger: 77.22681724192779\n"
     ]
    }
   ],
   "source": [
    "# provided code:\n",
    "\n",
    "def accuracy(sys,gold):\n",
    "    \"\"\"\n",
    "    Function for evaluating tagging accuracy w.r.t. a gold standard test set (gold).\n",
    "    \"\"\"\n",
    "    assert(len(sys) == len(gold))\n",
    "    corr = 0\n",
    "    tot = 0\n",
    "    pos_itos = pos_vocab.get_itos()\n",
    "    for s, g in zip(sys,gold):\n",
    "        assert(len(s) == len(g.pos))\n",
    "        corr += sum([1 if x==pos_itos[y] else 0 for x,y in zip(s,g.pos)])\n",
    "        tot += len(s)\n",
    "    return corr * 100.0 / tot\n",
    "\n",
    "print(\"Accuracy for baseline majority class tagger:\",accuracy(output_tags,dev_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: The POS tagger\n",
    "\n",
    "In this exercise, you will build a basic BiLSTM POS tagger. The tagger:\n",
    "\n",
    "1. Embeds word tokens in the input sentence.\n",
    "2. Passes the embeddings through a bidirectional LSTM layer.\n",
    "3. Predicts POS tags using a feed-forward network and log softmax layer.\n",
    "\n",
    "When you are implementing the POS tagger, remember to always keep track of the input and output sizes of all of you tensors. It is very important to check that these are correct. It is also important to understand what your dimensions refer to.\n",
    "\n",
    "Let's start by loading a few necessary libraries and setting hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.functional import log_softmax, relu\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from random import random, seed, shuffle\n",
    "\n",
    "# Ensure reproducible results by setting random seeds to 0.\n",
    "seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "import re\n",
    "\n",
    "# Hyperparameters\n",
    "EMBEDDING_DIM=300\n",
    "RNN_HIDDEN_DIM=50\n",
    "RNN_LAYERS=1\n",
    "BATCH_SIZE=1\n",
    "EPOCHS=5\n",
    "\n",
    "# Maximum length of generated output word forms.\n",
    "MAXWFLEN=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: LSTM layer\n",
    "\n",
    "rubric={accuracy:15}\n",
    "\n",
    "You should implement a `BidirectionalLSTM` class which is used to encode a sequence of word embeddings into  representations. `BidirectionalLSTM` encapsulates two LSTM networks: `self.forward_rnn` and `self.backward_rnn` which you should initialize in `BidirectionalLSTM.__init__`. Both should have:\n",
    "\n",
    "1. Embedding dimension `self.embedding_dim` (this is a parameter to the `__init__` function)\n",
    "1. Hidden dimension `RNN_HIDDEN_DIM` \n",
    "1. Layer count `RNN_LAYERS`\n",
    "\n",
    "Your second task is to implement the `BidirectionalLSTM.forward` function. As argument, the function takes a `torch.Tensor` `sequence` which has size `(sequence_length,1,EMBEDDING_DIM)`. This tensor contains the word embeddings for the input sentence.  \n",
    "\n",
    "You should pass the `sequence` to `self.forward_rnn` which returns:\n",
    "\n",
    "1. a sequence $f_1,...,f_n$ of forward hidden states represented as a tensor `fwd_hss` having size `(sequence_length,1,RNN_HIDDEN_DIM)` and\n",
    "1. a pair `(fwd_hs, fwd_cs)`, where:\n",
    "   1. `fwd_hs` is the final forward hidden state having dimension `(1,1,RNN_HIDDEN_DIM)`.\n",
    "   1. `fwd_cs` is the final forward cell state having dimension `(1,1,RNN_HIDDEN_DIM)`.\n",
    "   \n",
    "You should pass the **reversed** `sequence` to `self.backward_rnn` (**HINT**: [`torch.flip`](https://pytorch.org/docs/stable/torch.html#torch.flip) can be useful here) which returns:\n",
    "\n",
    "1. a sequence $b_n,...,b_1$ of backward hidden states represented as a tensor `bwd_hss` having size `(sequence_length,1,RNN_HIDDEN_DIM)` (NOTE! the backward states are reversersed here) \n",
    "1. and a pair `(bwd_hs, bwd_cs)`, where:\n",
    "   1. `bwd_hs` is the final backward hidden state having dimension `(1,1,RNN_HIDDEN_DIM)`.\n",
    "   1. `bwd_cs` is the final backward cell state having dimension `(1,1,RNN_HIDDEN_DIM)`.\n",
    "   \n",
    "The `forward` function should return a tensor `hss` having dimension `(sequence_length, 1, 2*self.hidden_dim)`, where `hss[i]` represents the concatenation of the $i$th forward hidden state $f_i$ and the $i$th backward hidden state $b_i$ (**HINT**: Again `torch.flip` can be useful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=EMBEDDING_DIM):\n",
    "        super(BidirectionalLSTM,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # your code here\n",
    "        # `BidirectionalLSTM` encapsulates two LSTM networks: \n",
    "        # `self.forward_rnn` and `self.backward_rnn` which you should initialize \n",
    "            # `self.embedding_dim` (this is a parameter to the `__init__` function)\n",
    "            # `RNN_HIDDEN_DIM` \n",
    "            # `RNN_LAYERS`\n",
    "\n",
    "    # `forward` takes a `sequence` which has size `(sequence_length,1,EMBEDDING_DIM)`. \n",
    "    # This tensor contains the word embeddings for the input sentence. \n",
    "    def forward(self,sequence):\n",
    "        # your code here\n",
    "        # `fwd_hss` by `forward_rnn`\n",
    "        # `bwd_hss` by `backward_rnn` (your sequence should be reversersed here using `torch.flip` )\n",
    "\n",
    "        # return  concat of `fwd_hss` and `bwd_hss` where you should use again `torch.flip` for bwd_hss\n",
    "        return ...\n",
    "        # your code here\n",
    "        \n",
    "# Assertions to check that your code returns objects of the correct size (not a guarantee that your code works).\n",
    "# assert(BidirectionalLSTM()(torch.zeros(10,1,EMBEDDING_DIM)).size() == (10,1,2*RNN_HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve tagging accuracy for OOV words, we need to use word dropout. It takes two arguments:\n",
    "1. A `torch.Tensor` `sequence` of size `(sequence_length,1)` and\n",
    "1. A float `word_dropout` in the interval `[0,1]`.\n",
    "During training, the function randomly replaces words by `WORD.vocab.stoi[UNK]` with probability 'word_dropout'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided code:\n",
    "def drop_words(sequence,word_dropout):\n",
    "    seq_len, _ = sequence.size()\n",
    "    dropout_sequence = sequence.clone()\n",
    "    for i in range(1,seq_len-1):\n",
    "        if random() < word_dropout:\n",
    "            dropout_sequence[i,0] = word_vocab[\"<unk>\"]\n",
    "    return dropout_sequence\n",
    "    \n",
    "# Assertions to check that your code returns objects of the correct size (not a guarantee that your code works).\n",
    "# assert(drop_words(torch.zeros(10,1),0.5).size() == (10,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2 Sentence Encoder \n",
    "\n",
    "rubric={accuracy:15}\n",
    "\n",
    "Your next task is to build a class `SentenceEncoder` which takes an example (from `train_iter`, `dev_iter` or `test_iter`) as input and returns a sequence of LSTM hidden states given by `BidirectionalLSTM`.\n",
    "\n",
    "You first task is to initialize the `SentenceEncoder` class. You will initialize 3 class-members:\n",
    "1. `self.vocabulary` which is just an alias for `WORD.vocab.stoi`.\n",
    "1. `self.embeddings` which is a `torch.nn.Embedding` having input dimension `len(self.vocabulary)` and output dimension `EMBEDDING_DIM`.\n",
    "1. `self.rnn` which is a `BidirectionalLSTM` object.\n",
    "\n",
    "You should them implement `SentenceEncoder.forward` which takes as example `ex` as input. Additionally, it takes another parameter `word_dropout` which is the probability for word dropout on the sentence `ex`. The function should:\n",
    "1. Perform word dropout on `ex` by calling the `drop_words` function above.\n",
    "1. Embed the resulting tensor resulting in a tensor `embedded`.\n",
    "1. Run `self.rnn` on embedded.\n",
    "1. Return the resulting representation tensor. However, `ex.word` represents a sentence where we have appended an initial symbol `START` and final symbol `END`. You need to therefore clip the first and last representation vector before returning the output of `self.rnn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentenceEncoder,self).__init__()\n",
    "        # your code here\n",
    "        # `self.vocabulary` which is just an alias for `word_vocab`.\n",
    "        # `self.embedding` which is a `nn.Embedding` with the length of `vocabulary` and `EMBEDDING_DIM`\n",
    "        # `self.rnn` which is a `BidirectionalLSTM` object.\n",
    "    \n",
    "        \n",
    "    def forward(self,ex,word_dropout):\n",
    "        # your code here\n",
    "        # `drop_words` using `ex.word`, `word_dropout` \n",
    "        # -> `self.embedding`.\n",
    "        # -> `self.rnn`\n",
    "\n",
    "        # return the ressult of `self.rnn`. \n",
    "        # need to therefore clip the first and last representation vector (<start> and <end>) before returning the output\n",
    "        return ...\n",
    "       \n",
    "ex = next(iter(dev_iter))\n",
    "sentence_length = ex.word.size()[0] - 2\n",
    "assert(SentenceEncoder()(ex,0.5).size() == (sentence_length, 1, 2*RNN_HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.3: Prediction Layer\n",
    "\n",
    "rubric={accuracy:15}\n",
    "\n",
    "Your next task is to implement a feed-forward network `FeedForward` which is used to predict tags from LSTM representations. The constructor `feedForward.__init__` takes two arguments `input_dim` and `output_dim` representing the input and output dimension of the network, respectively. \n",
    "Your first task is to complete the function `FeedForward.__init__` by initializing two linear layers:\n",
    "1. `self.linear1` having input dimension `input_dim` and output dimension `input_dim` and\n",
    "2. `self.linear2` having input dimension `input_dim` and output dimension `output_dim`.\n",
    "\n",
    "Your second task is to implement the function `FeedForward.forward`. As input, the function takes `tensor` which is a torch.Tensor object having size `(sequence_length, 1, input_dim)`. It then:\n",
    "1. Applies `self.linear1` followed by a ReLU activation function on `tensor` and\n",
    "2. then passes the result through `self.linear2` and a `log_softmax` layer and finally returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        # your code here\n",
    "        # `self.linear1` having input dimension `input_dim` and output dimension `input_dim` \n",
    "        # `self.linear2` having input dimension `input_dim` and output dimension `output_dim`\n",
    "\n",
    "        \n",
    "    def forward(self,tensor):\n",
    "        # your code here\n",
    "        # applies `self.linear1` followed by a ReLU activation function (`relu`) on `tensor` \n",
    "        # then, passes the result through `self.linear2` and a `log_softmax` layer and finally returns the result.\n",
    "        \n",
    "\n",
    "        return ...\n",
    "        # your code here\n",
    "        \n",
    "# Assertions to check that your code returns objects of the correct size (not a guarantee that your code works).\n",
    "assert(FeedForward(2*RNN_HIDDEN_DIM,100)(torch.zeros(10,1,2*RNN_HIDDEN_DIM)).size() == (10,1,100))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging sentences and training the model\n",
    "\n",
    "Now it's time to put together all the components that you built so far. `SimplePOSTagger` is a wrapper around a `SentenceEncoder` and `FeedForward` layer. It has a `forward` method which returns a tensor `res` where `res[i,j]` represents the log probability of tag `POS.itos[j]` for the word at position `i` in our input sentences. \n",
    "\n",
    "The function `tag` gets POS tags for a dataset `data`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided code:\n",
    "class SimplePOSTagger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplePOSTagger,self).__init__()\n",
    "        self.tagset_size = len(pos_vocab)\n",
    "        \n",
    "        self.sentence_encoder = SentenceEncoder()\n",
    "        self.hidden2tag = FeedForward(2*RNN_HIDDEN_DIM,self.tagset_size)\n",
    "        \n",
    "    def forward(self,ex, word_dropout=0):\n",
    "        states = self.sentence_encoder(ex,word_dropout)\n",
    "        return self.hidden2tag(states)\n",
    "\n",
    "    def tag(self,data):\n",
    "        with torch.no_grad():\n",
    "            results = []\n",
    "            pos_itos = pos_vocab.get_itos()\n",
    "            for ex in data:\n",
    "                tags = self(ex).argmax(dim=2).squeeze(1)\n",
    "                results.append([pos_itos[i] for i in tags])\n",
    "            return results\n",
    "        \n",
    "pos_size = len(pos_vocab)\n",
    "ex = next(iter(dev_iter))\n",
    "assert(SimplePOSTagger()(ex).size() == (ex.word.size()[0]-2,1,pos_size))\n",
    "assert(len(SimplePOSTagger().tag([ex])[0]) == ex.word.size()[0] -2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with the `SimplePOSTagger` class, you can now train your tagger using the following code. You should get to around 75% tagging accuracy on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Example 1000 of 1000\n",
      "Average loss per example: 1.2512\n",
      "Development accuracy: 69.94\n",
      "Epoch 2: Example 1000 of 1000\n",
      "Average loss per example: 0.5149\n",
      "Development accuracy: 72.72\n",
      "Epoch 3: Example 1000 of 1000\n",
      "Average loss per example: 0.2772\n",
      "Development accuracy: 73.44\n",
      "Epoch 4: Example 1000 of 1000\n",
      "Average loss per example: 0.1808\n",
      "Development accuracy: 73.15\n",
      "Epoch 5: Example 1000 of 1000\n",
      "Average loss per example: 0.1451\n",
      "Development accuracy: 75.57\n"
     ]
    }
   ],
   "source": [
    "# provided code:\n",
    "\n",
    "tagger = SimplePOSTagger()\n",
    "optimizer = Adam(tagger.parameters())\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i,ex in enumerate(train_iter):\n",
    "        print(\"Epoch %u: Example %u of %u\" % (epoch+1, i+1,len(train)),end=\"\\r\")\n",
    "        tagger.zero_grad()\n",
    "        output = tagger(ex,word_dropout=0.05).squeeze(dim=1)\n",
    "        gold = ex.pos.squeeze(dim=1)\n",
    "        loss = loss_function(output,gold)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss.detach().numpy()\n",
    "    print(\"\\nAverage loss per example: %.4f\" % (tot_loss/len(train_iter)))\n",
    "    sys_dev = tagger.tag(dev_iter)\n",
    "    print(\"Development accuracy: %.2f\" % accuracy(sys_dev, dev_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that this is almost the same accuracy as for our baseline model. You can get a bit higher if you raise the number of epochs. If you really want better accuracy, you'll have to implement a character-level model and use pretrained embeddings. These can get you up to 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Character-based tagging (optional)\n",
    "\n",
    "In this exercise, you will extend your basic BiLSTM POS tagger to include character-based embeddings. In contrast to the basic tagger, the character-based tagger computes word embeddings as a concatenation of a token embedding derived from a regular `nn.Embedding` object and a character-based embedding which is computed by a bidirectional LSTM.\n",
    "\n",
    "Again, always remember to keep track of the input and output sizes of all of you tensors. It is very important to check that these are correct.\n",
    "\n",
    "#### Exercise 4.1 optional\n",
    "rubric={accuracy:3}\n",
    "\n",
    "Start by implementing the `CharEmbedding` class which computes character-based embeddings using a bidirectional LSTM. Your first task is to implement the `CharEmbedding.__init__` function. Initialize: \n",
    "\n",
    "* `self.char_set` which is just an alias for `CHAR.vocab.stoi` (which numericalizes individual characters like 'a').\n",
    "* `self.embeddings` which is a `torch.nn.Embedding` having input dimension `len(self.char_set)` and output dimension `EMBEDDING_DIM`.\n",
    "* `self.rnn` which is a `nn.LSTM` object (note, not `BidirectionalLSTM`!). You should set the embedding dimension to `EMBEDDING_DIM`, hidden dimension to `RNN_HIDDEN_DIM`, layer count to `RNN_LAYERS` and `bidirectional` to `True`.\n",
    "\n",
    "After initializing `CharEmbedding`, you should implement the `CharEmbedding.forward` method. The method takes an example `ex` which represents a sentence as input. For each word in `ex`, `forward` embeds the characters in the word and passes the character embeddings through `self.rnn`. It then stores the final hidden state returned by `self.rnn` in a list and finally returns a tensor representing these states for every word in the sentence. \n",
    "\n",
    "The function `forward` takes two inputs:\n",
    "\n",
    "* `ex` and example representing the input sentence, and\n",
    "* `char_dropout` a real number between 0 and 1, which represents the probability for dropping a character during training.\n",
    "\n",
    "We are interested in `ex.char` which is a tuple containing three tensors:\n",
    "\n",
    "1. `ex.char[0]` is a `1 x sentence_len x char_count` tensor, where `char_count` is the length of the **longest** word in the sentence. \n",
    "1. `ex.char[1]` is a scalar representing the sentence length\n",
    "1. `ex.char[2]` is a tensor of shape `1 x sentence_length` which contains the lengths of each word in the sentence. E.g. `ex.char[2][0]` is the length of the first word.\n",
    "\n",
    "E.g. `ex.char[0][:,0,:]` represents the first word. The tensor might look like this:\n",
    "```\n",
    "tensor([[ 2, 29, 13, 13,  3,  1,  1,  1,  1,  1,  1]])\n",
    "```\n",
    "The word has 5 actual characters and the rest of the characters are padding characters. In this case, `ex[2][0,0] == 5`.  \n",
    "\n",
    "To implement `forward`, you should:\n",
    "\n",
    "1. Initialize a list `embeddings`.\n",
    "2. Loop through the word indices `i` in `1 ... sentence_length`. \n",
    "3. Each word `ex.char[0][:,i,:]` will contain `ex.char[2][0,i]` characters, the rest are padding. Initialize a tensor `word` which contains all the characters from index `0` up to and including `ex.char[2][0,i] - 1`. Note that `word` should be an order 3 tensor, so you'll need to call `unsqueeze(1)`. \n",
    "4. We will now perform character dropout. We can use the function `drop_words()` to accomplish this. Call the function `drop_words()` passing `word` and `char_dropout` as arguments.\n",
    "5. Embed the characters in `word` and pass them through `self.rnn`. This should give you a tensor of size `2 x 1 x RNN_HIDDEN_DIM` (2 because `self.rnn` is bidirectional).\n",
    "6. Reshape the final state into a `1 x 1 x 2*RNN_HIDDEN_DIM` tensor and append it to `embeddings`.\n",
    "7. After you've looped through the words in `ex`, append a zero tensor of dimension `1 x 1 x 2*RNN_HIDDEN_DIM` at the front and end of `embeddings`. We need to do this to take into account start and end of sentence markers (which are not present in `ex.char`).\n",
    "8. Now, `embeddings` should contain one character-based embedding for every word in the sentence + two embeddings for the start and end of sequence markers. Concatenate these into a `(sentence_length + 2) x 1 x 2*RNN_HIDDEN_DIM` tensor and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharEmbedding,self).__init__()\n",
    "\n",
    "        # your code here\n",
    "        # it should be SAME as in `SentenceEncoder` by using char_vocab and its length;\n",
    "        # otherwise, you will use `nn.LSTM` instead of `BidirectionalLSTM` with \n",
    "        #   EMBEDDING_DIM, RNN_HIDDEN_DIM, RNN_LAYERS, `bidirectional=True``\n",
    "        #your code here\n",
    "        \n",
    "    def forward(self,ex,char_dropout):\n",
    "        # your code here\n",
    "        # you iterate word by word, then\n",
    "        #   it should be SAME as in `SentenceEncoder` (say, you are making a `WordEncoder`)\n",
    "\n",
    "\n",
    "        # `ex.char[0]` = `1 x sentence_len x char_count` tensor\n",
    "        # `ex.char[1]` = the sentence length\n",
    "        # `ex.char[2]` = `1 x sentence_length` which contains the lengths of each word in the sentence. \n",
    "        #   E.g. `ex.char[2][0]` is the length of the first word. \n",
    "\n",
    "        # then, iterate `i` word by word, \n",
    "        # ex.char[2][i]         -> the length of ith word;\n",
    "        # ex.char[0][:,i,:]     -> the ith word\n",
    "        # then you should remove 'padding' in ith word, and unsqueeze it (see what we did during `collate_batch()`)\n",
    "\n",
    "        # now, same as in `SentenceEncoder`: \n",
    "        #     embedding and rnn;  \n",
    "        \n",
    "        # reshape the final state into a `1 x 1 x 2*RNN_HIDDEN_DIM` (1,1,-1) and append it to `embeddings`.\n",
    "        # after iteration for `ex`, \n",
    "        #     append a zero tensor of dimension `1 x 1 x 2*RNN_HIDDEN_DIM` \n",
    "        #     at the front and end of `embeddings`. \n",
    "        #     for start and end of sentence markers (which are not present in `ex.char`)\n",
    "        \n",
    "        \n",
    "        # finally, concatenate `embedding` into a `(sentence_length + 2) x 1 x 2*RNN_HIDDEN_DIM` tensor and return it.\n",
    "        return ...\n",
    "        # your code here\n",
    "\n",
    "ex = next(iter(dev_iter))\n",
    "sentence_length = ex.word.size()[0]\n",
    "assert(CharEmbedding()(ex,0.5).size() == (sentence_length, 1, 2*RNN_HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.2 optional\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Your next task is to build a class `CharSentenceEncoder` which takes an example `ex` as input and returns a sequence of LSTM hidden states.\n",
    "\n",
    "You first task is to initialize the `CharSentenceEncoder` class. Start by copying your initialization code from `SentenceEncoder`, but change the initialization of `self.rnn` slightly. It should have embedding dimension `EMBEDDING_DIM+2*RNN_HIDDEN_DIM` because we are feeding in concatenated token and character-based embeddings to `self.rnn`. You should also initialize `self.char_embedding`, which is a `CharEmbedding` object.  \n",
    "\n",
    "You should them implement `CharSentenceEncoder.forward` which takes as example `ex` as input. Additionally, it takes two other parameters `word_dropout` and `char_dropout` which represent the word and character dropout probabilities, respectively. The function should:\n",
    "1. Perform word dropout on `ex` by calling the `drop_words` function above.\n",
    "1. Embed the resulting tensor resulting in a tensor `word_embedded`.\n",
    "1. Embed `ex` using `self.char_embedding` giving a tensor `char_embedded` (remember to pass `char_dropout` as argument).\n",
    "1. Concatenate `word_embedded` and `char_embedded` into a `(sentence_length + 2) x 1 x (EMBEDDING_DIM + 2*RNN_HIDDEN_DIM)` tensor. \n",
    "1. Run `self.rnn` on `embedded`.\n",
    "1. Return the resulting representation tensor. Clip the first and last representation vector before returning the output of `self.rnn` (these correspond to the start and end of sequence tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSentenceEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharSentenceEncoder,self).__init__()\n",
    "\n",
    "        # your code here\n",
    "        # exactly same as in previous `SentenceEncoder` \n",
    "        # and add `self.char_embedding = `CharEmbedding()`\n",
    "        \n",
    "    def forward(self,ex,word_dropout,char_dropout):\n",
    "        # your code here\n",
    "        # exactly same as in previous `SentenceEncoder` \n",
    "        # and add `char_embedded = char_embedding`\n",
    "        \n",
    "        # then, concatenate `word_embedded` and `char_embedded` as one big `embedded`\n",
    "        # rnn, return it (by removing <start> and <end> as in `SentenceEncoder`)\n",
    "\n",
    "\n",
    "ex = next(iter(dev_iter))\n",
    "sentence_length = ex.word.size()[0] - 2\n",
    "assert(CharSentenceEncoder()(ex,0.5,0.5).size() == (sentence_length, 1, 2*RNN_HIDDEN_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines and trains a character-based POS tagger which uses the classes that you implemented above. You should get accuracy > 80% on the development data.\n",
    "\n",
    "Note that it can be much slower to train `CharPOSTagger` than `SimplePOSTagger`. This is partly due to the looping in `CharEmbedding`. There are more efficient ways to handle this and we'll see some techniques next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Example 1000 of 1000\n",
      "Average loss per example: 0.9608\n",
      "Development accuracy: 79.80\n",
      "Epoch 2: Example 1000 of 1000\n",
      "Average loss per example: 0.3046\n",
      "Development accuracy: 82.46\n",
      "Epoch 3: Example 1000 of 1000\n",
      "Average loss per example: 0.1707\n",
      "Development accuracy: 83.04\n",
      "Epoch 4: Example 1000 of 1000\n",
      "Average loss per example: 0.1140\n",
      "Development accuracy: 83.05\n",
      "Epoch 5: Example 1000 of 1000\n",
      "Average loss per example: 0.0955\n",
      "Development accuracy: 82.95\n"
     ]
    }
   ],
   "source": [
    "class CharPOSTagger(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharPOSTagger,self).__init__()\n",
    "        self.tagset_size = len(pos_vocab)\n",
    "        \n",
    "        self.sentence_encoder = CharSentenceEncoder()\n",
    "        self.hidden2tag = FeedForward(2*RNN_HIDDEN_DIM,self.tagset_size)\n",
    "        \n",
    "    def forward(self,ex, word_dropout=0, char_dropout=0):\n",
    "        states = self.sentence_encoder(ex,word_dropout,char_dropout)\n",
    "        return self.hidden2tag(states)\n",
    "\n",
    "    def tag(self,data):\n",
    "        with torch.no_grad():\n",
    "            results = []\n",
    "            pos_itos=pos_vocab.get_itos()\n",
    "            for ex in data:\n",
    "                tags = self(ex).argmax(dim=2).squeeze(1)\n",
    "                results.append([pos_itos[i] for i in tags])\n",
    "            return results\n",
    "        \n",
    "pos_size = len(pos_vocab)\n",
    "ex = next(iter(dev_iter))\n",
    "assert(CharPOSTagger()(ex).size() == (ex.word.size()[0]-2,1,pos_size))\n",
    "assert(len(CharPOSTagger().tag([ex])[0]) == ex.word.size()[0] -2) \n",
    "\n",
    "tagger = CharPOSTagger()\n",
    "optimizer = Adam(tagger.parameters())\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for i,ex in enumerate(train_iter):\n",
    "        print(\"Epoch %u: Example %u of %u\" % (epoch+1, i+1,len(train_iter)),end=\"\\r\")\n",
    "        tagger.zero_grad()\n",
    "        output = tagger(ex,word_dropout=0.05).squeeze(dim=1)\n",
    "        gold = ex.pos.squeeze(dim=1)\n",
    "        loss = loss_function(output,gold)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss.detach().numpy()\n",
    "    print(\"\\nAverage loss per example: %.4f\" % (tot_loss/len(train_iter)))\n",
    "    sys_dev = tagger.tag(dev_iter)\n",
    "    print(\"Development accuracy: %.2f\" % accuracy(sys_dev, dev_iter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
